{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import wandb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.hooks import EarlyStoppingHook\n",
    "from mmengine.visualization import Visualizer, WandbVisBackend\n",
    "from mmdet.utils import setup_cache_size_limit_of_dynamo\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "# mmdetection을 시스템 경로에 추가\n",
    "sys.path.insert(0, \"../mmdetection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 맞춤형 학습 설정\n",
    "config_path = './configs/grounding_dino/grounding_dino_swin-b_finetune_16xb2_1x_coco.py'  # DINO 설정 파일 경로\n",
    "work_dir = './work_dirs/co_dino_custom'  # 로그와 모델을 저장할 디렉토리 경로\n",
    "train_data_root = '/data/ephemeral/home/dataset/'  # 학습 데이터 경로\n",
    "original_ann_file = '/data/ephemeral/home/dataset/train.json'  # 전체 데이터 어노테이션 파일 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 설정\n",
    "classes = (\n",
    "    \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\",\n",
    "    \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"\n",
    ")\n",
    "num_classes = len(classes)  # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증 데이터셋 나누기 (멀티라벨 스트라티파이드 분할)\n",
    "with open(original_ann_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# 이미지 ID 리스트 가져오기\n",
    "image_ids = [image['id'] for image in annotations['images']]\n",
    "\n",
    "# 이미지 ID와 해당 이미지에 포함된 클래스 목록 매핑\n",
    "image_id_to_classes = {image_id: [] for image_id in image_ids}\n",
    "for ann in annotations['annotations']:\n",
    "    image_id = ann['image_id']\n",
    "    category_id = ann['category_id']\n",
    "    if category_id not in image_id_to_classes[image_id]:\n",
    "        image_id_to_classes[image_id].append(category_id)\n",
    "\n",
    "# 멀티라벨 인코딩을 위한 이진 매트릭스 생성\n",
    "num_images = len(image_ids)\n",
    "label_matrix = np.zeros((num_images, num_classes))\n",
    "image_id_to_index = {image_id: idx for idx, image_id in enumerate(image_ids)}\n",
    "for image_id, class_ids in image_id_to_classes.items():\n",
    "    idx = image_id_to_index[image_id]\n",
    "    for class_id in class_ids:\n",
    "        label_matrix[idx, class_id - 1] = 1  # category_id는 1부터 시작\n",
    "\n",
    "# 멀티라벨 스트라티파이드 셔플 스플릿 사용\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = next(msss.split(image_ids, label_matrix))\n",
    "\n",
    "# 인덱스를 이미지 ID로 변환\n",
    "train_ids = [image_ids[idx] for idx in train_indices]\n",
    "val_ids = [image_ids[idx] for idx in val_indices]\n",
    "\n",
    "# 학습 및 검증 데이터 어노테이션 생성\n",
    "train_annotations = {\n",
    "    'images': [img for img in annotations['images'] if img['id'] in train_ids],\n",
    "    'annotations': [ann for ann in annotations['annotations'] if ann['image_id'] in train_ids],\n",
    "    'categories': annotations['categories']\n",
    "}\n",
    "val_annotations = {\n",
    "    'images': [img for img in annotations['images'] if img['id'] in val_ids],\n",
    "    'annotations': [ann for ann in annotations['annotations'] if ann['image_id'] in val_ids],\n",
    "    'categories': annotations['categories']\n",
    "}\n",
    "\n",
    "# 분할된 어노테이션을 파일로 저장\n",
    "train_ann_file = '/data/ephemeral/home/dataset/train_split.json'\n",
    "val_ann_file = '/data/ephemeral/home/dataset/val_split.json'\n",
    "\n",
    "with open(train_ann_file, 'w') as f:\n",
    "    json.dump(train_annotations, f)\n",
    "with open(val_ann_file, 'w') as f:\n",
    "    json.dump(val_annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어노테이션 파일 수정: category_id를 1부터 시작하도록 조정\n",
    "def increment_category_id(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 'categories' 섹션의 'id'를 1부터 시작하도록 수정\n",
    "    id_mapping = {}\n",
    "    for category in data['categories']:\n",
    "        old_id = category['id']\n",
    "        new_id = old_id + 1\n",
    "        id_mapping[old_id] = new_id\n",
    "        category['id'] = new_id\n",
    "\n",
    "    # 'annotations' 섹션의 'category_id'를 매핑에 따라 수정\n",
    "    for ann in data['annotations']:\n",
    "        old_cat_id = ann['category_id']\n",
    "        if old_cat_id in id_mapping:\n",
    "            ann['category_id'] = id_mapping[old_cat_id]\n",
    "        else:\n",
    "            print(f\"Warning: annotation id {ann['id']} has invalid category_id {old_cat_id}\")\n",
    "\n",
    "    # 수정된 데이터를 원래 파일에 저장\n",
    "    with open(annotation_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# 어노테이션 파일에 category_id를 1부터 시작하도록 수정\n",
    "increment_category_id(train_ann_file)\n",
    "increment_category_id(val_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoungtae0818\u001b[0m (\u001b[33myoungtae0818-naver\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/baseline/mmdetection/wandb/run-20241018_003904-cpuls2el</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/cpuls2el' target=\"_blank\">grounding_dino_swin-b_finetune_16xb2_1x_coco_20241018_003904</a></strong> to <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/cpuls2el' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection/runs/cpuls2el</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Run Initialized: grounding_dino_swin-b_finetune_16xb2_1x_coco_20241018_003904\n"
     ]
    }
   ],
   "source": [
    "# 설정 파일 로드\n",
    "cfg = Config.fromfile(config_path)\n",
    "\n",
    "# 작업 디렉토리 수정\n",
    "cfg.work_dir = work_dir  # 로그와 모델 저장을 위한 작업 디렉토리 수정\n",
    "\n",
    "# backbone의 checkpoint 비활성화\n",
    "cfg.model.backbone.with_cp = False\n",
    "\n",
    "# encoder의 checkpoint 비활성화\n",
    "cfg.model.encoder.num_cp = 0\n",
    "\n",
    "\n",
    "# EarlyStoppingHook 추가\n",
    "early_stopping_hook = dict(\n",
    "    type='EarlyStoppingHook',\n",
    "    monitor='bbox_mAP',\n",
    "    rule='greater',\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    check_finite=True,\n",
    "    stopping_threshold=None\n",
    ")\n",
    "\n",
    "# cfg.default_hooks에 EarlyStoppingHook 추가\n",
    "cfg.default_hooks.update(\n",
    "    early_stopping=early_stopping_hook\n",
    ")\n",
    "\n",
    "# WandB 초기화 (Runner 전에)\n",
    "run_name = f'grounding_dino_swin-b_finetune_16xb2_1x_coco_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "wandb.init(\n",
    "    project='Object_detection',\n",
    "    name=run_name,\n",
    "    config=cfg.to_dict(),\n",
    "    allow_val_change=True,\n",
    "    reinit=True\n",
    ")\n",
    "print(f\"WandB Run Initialized: {run_name}\")\n",
    "\n",
    "# WandbVisBackend 설정\n",
    "wandb_vis_backend = dict(\n",
    "    type='WandbVisBackend',\n",
    "    save_dir=cfg.work_dir,  # 저장할 디렉토리\n",
    "    init_kwargs=dict(\n",
    "        project='Object_detection',  # WandB 프로젝트 이름\n",
    "        name=run_name,                # 고유한 실행 이름\n",
    "        allow_val_change=True         # 설정 값 변경 허용\n",
    "    ),\n",
    "    define_metric_cfg=None,\n",
    "    commit=True,\n",
    "    log_code_name=None,\n",
    "    watch_kwargs=None\n",
    ")\n",
    "\n",
    "# Visualizer 설정을 Runner의 visualizer 필드로 추가\n",
    "cfg.visualizer = dict(\n",
    "    type='Visualizer',\n",
    "    vis_backends=[\n",
    "        wandb_vis_backend  # WandbVisBackend 추가\n",
    "    ],\n",
    "    name='visualizer'  # Visualizer 이름 (옵션)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 루트 경로 수정\n",
    "cfg.train_dataloader.dataset.ann_file = train_ann_file  # 학습 데이터 어노테이션 파일 경로 수정\n",
    "cfg.train_dataloader.dataset.data_prefix = dict(img=train_data_root)  # 학습 데이터 이미지 경로 수정\n",
    "\n",
    "cfg.val_dataloader.dataset.ann_file = val_ann_file  # 검증 데이터 어노테이션 파일 경로 수정\n",
    "cfg.val_dataloader.dataset.data_prefix = dict(img=train_data_root)  # 검증 데이터 이미지 경로 수정\n",
    "\n",
    "# 클래스 설정을 데이터셋의 metainfo에 추가\n",
    "cfg.train_dataloader.dataset.metainfo = dict(classes=classes)  # 학습 데이터셋 클래스 설정\n",
    "cfg.val_dataloader.dataset.metainfo = dict(classes=classes)    # 검증 데이터셋 클래스 설정\n",
    "\n",
    "# 데이터 파이프라인 수정: 마스크 관련 부분 제거 및 불필요한 단계 제거\n",
    "def modify_pipeline(pipeline):\n",
    "    new_pipeline = []\n",
    "    for step in pipeline:\n",
    "        if step['type'] == 'LoadAnnotations':\n",
    "            step['with_bbox'] = True\n",
    "            step['with_mask'] = False  # 마스크 관련 부분 제거\n",
    "        if step['type'] == 'CopyPaste':\n",
    "            continue  # CopyPaste 변환 제거\n",
    "        new_pipeline.append(step)\n",
    "    return new_pipeline\n",
    "\n",
    "cfg.train_dataloader.dataset.pipeline = modify_pipeline(cfg.train_dataloader.dataset.pipeline)\n",
    "cfg.val_dataloader.dataset.pipeline = modify_pipeline(cfg.val_dataloader.dataset.pipeline)\n",
    "\n",
    "# 클래스 수 수정\n",
    "# bbox_head가 리스트인 경우 모든 헤드에 대해 num_classes 설정\n",
    "if isinstance(cfg.model.bbox_head, list):\n",
    "    for head in cfg.model.bbox_head:\n",
    "        head['num_classes'] = num_classes\n",
    "else:\n",
    "    cfg.model.bbox_head['num_classes'] = num_classes\n",
    "\n",
    "# # roi_head 내의 bbox_head도 설정\n",
    "# if isinstance(cfg.model.roi_head, list):\n",
    "#     for roi_head in cfg.model.roi_head:\n",
    "#         if 'bbox_head' in roi_head:\n",
    "#             roi_head['bbox_head']['num_classes'] = num_classes\n",
    "# else:\n",
    "#     if 'bbox_head' in cfg.model.roi_head:\n",
    "#         cfg.model.roi_head['bbox_head']['num_classes'] = num_classes\n",
    "\n",
    "# # query_head도 num_classes 설정\n",
    "# if isinstance(cfg.model.query_head, list):\n",
    "#     for q_head in cfg.model.query_head:\n",
    "#         q_head['num_classes'] = num_classes\n",
    "# else:\n",
    "#     cfg.model.query_head['num_classes'] = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 관련 헤드에 대해 num_classes가 올바르게 설정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 추가: 모델의 모든 관련 헤드에 num_classes가 올바르게 설정되었는지 확인\n",
    "def verify_num_classes(cfg, num_classes):\n",
    "    # bbox_head\n",
    "    if isinstance(cfg.model.bbox_head, list):\n",
    "        for head in cfg.model.bbox_head:\n",
    "            assert head.get('num_classes') == num_classes, \"bbox_head num_classes 설정 오류\"\n",
    "    else:\n",
    "        assert cfg.model.bbox_head.get('num_classes') == num_classes, \"bbox_head num_classes 설정 오류\"\n",
    "    \n",
    "    # # roi_head.bbox_head\n",
    "    # if isinstance(cfg.model.roi_head, list):\n",
    "    #     for roi_head in cfg.model.roi_head:\n",
    "    #         if 'bbox_head' in roi_head:\n",
    "    #             assert roi_head['bbox_head'].get('num_classes') == num_classes, \"roi_head.bbox_head num_classes 설정 오류\"\n",
    "    # else:\n",
    "    #     if 'bbox_head' in cfg.model.roi_head:\n",
    "    #         assert cfg.model.roi_head['bbox_head'].get('num_classes') == num_classes, \"roi_head.bbox_head num_classes 설정 오류\"\n",
    "    \n",
    "    # # query_head\n",
    "    # if isinstance(cfg.model.query_head, list):\n",
    "    #     for q_head in cfg.model.query_head:\n",
    "    #         assert q_head.get('num_classes') == num_classes, \"query_head num_classes 설정 오류\"\n",
    "    # else:\n",
    "    #     assert cfg.model.query_head.get('num_classes') == num_classes, \"query_head num_classes 설정 오류\"\n",
    "    \n",
    "    print(\"모든 관련 헤드에 대해 num_classes가 올바르게 설정되었습니다.\")\n",
    "\n",
    "verify_num_classes(cfg, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 혼합 정밀도 학습 사용 설정\n",
    "use_amp = False  # 자동 혼합 정밀도(AMP) 학습 사용 여부\n",
    "if use_amp:\n",
    "    cfg.optim_wrapper.type = 'AmpOptimWrapper'\n",
    "    cfg.optim_wrapper.loss_scale = 'dynamic'\n",
    "\n",
    "# 학습률 자동 스케일링 설정\n",
    "auto_scale_lr = False  # 학습률 자동 스케일링 사용 여부\n",
    "if auto_scale_lr:\n",
    "    if 'auto_scale_lr' in cfg and 'enable' in cfg.auto_scale_lr and 'base_batch_size' in cfg.auto_scale_lr:\n",
    "        cfg.auto_scale_lr.enable = True\n",
    "    else:\n",
    "        raise RuntimeError('설정 파일에 \"auto_scale_lr\" 또는 필요한 키가 없습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 설정 최적화\n",
    "cfg.train_dataloader.batch_size = 4  # 배치 사이즈를 1로 줄임\n",
    "cfg.val_dataloader.batch_size = 4\n",
    "\n",
    "cfg.train_dataloader.num_workers = 2  # 워커 수 줄이기\n",
    "cfg.val_dataloader.num_workers = 2\n",
    "\n",
    "# Prefetch factor와 persistent_workers 설정\n",
    "cfg.train_dataloader.prefetch_factor = 2\n",
    "cfg.train_dataloader.persistent_workers = False\n",
    "cfg.val_dataloader.prefetch_factor = 2\n",
    "cfg.val_dataloader.persistent_workers = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 재개 설정\n",
    "resume_training = False  # 학습 재개 여부 설정 (True로 설정 시 학습 재개)\n",
    "resume_checkpoint_path = './work_dirs/co_dino_custom/epoch_6.pth'  # 학습 재개 시 체크포인트 경로 지정\n",
    "if resume_training:\n",
    "    if resume_checkpoint_path is None:\n",
    "        cfg.resume = True\n",
    "        cfg.load_from = None\n",
    "    else:\n",
    "        cfg.resume = True\n",
    "        cfg.load_from = resume_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복적인 컴파일 횟수를 줄여 학습 속도 향상\n",
    "setup_cache_size_limit_of_dynamo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 설정 추가 및 수정\n",
    "cfg.evaluation = dict(interval=1, metric='bbox', save_best='auto')\n",
    "\n",
    "# 평가자(evaluator) 설정 수정\n",
    "if hasattr(cfg, 'val_evaluator'):\n",
    "    # 평가자가 딕셔너리 또는 리스트로 정의되어 있을 경우\n",
    "    if isinstance(cfg.val_evaluator, dict):\n",
    "        cfg.val_evaluator.ann_file = val_ann_file\n",
    "    elif isinstance(cfg.val_evaluator, list):\n",
    "        for evaluator in cfg.val_evaluator:\n",
    "            evaluator['ann_file'] = val_ann_file\n",
    "elif 'evaluation' in cfg:\n",
    "    # 평가 섹션 내에 ann_file을 추가\n",
    "    cfg.evaluation['ann_file'] = val_ann_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/18 00:39:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 792665384\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.1+cu116\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu116\n",
      "    OpenCV: 4.8.1\n",
      "    MMEngine: 0.10.1\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 792665384\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "10/18 00:39:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=32, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    early_stopping=dict(\n",
      "        check_finite=True,\n",
      "        min_delta=0.001,\n",
      "        monitor='bbox_mAP',\n",
      "        patience=5,\n",
      "        rule='greater',\n",
      "        stopping_threshold=None,\n",
      "        type='EarlyStoppingHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "evaluation = dict(interval=1, metric='bbox', save_best='auto')\n",
      "load_from = 'https://download.openmmlab.com/mmdetection/v3.0/grounding_dino/groundingdino_swinb_cogcoor_mmdet-55949c9c.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 100\n",
      "model = dict(\n",
      "    as_two_stage=True,\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        convert_weights=False,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            18,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.3,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=128,\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        pretrain_img_size=384,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer',\n",
      "        window_size=12,\n",
      "        with_cp=False),\n",
      "    bbox_head=dict(\n",
      "        contrastive_cfg=dict(),\n",
      "        loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            alpha=0.25,\n",
      "            gamma=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='FocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "        num_classes=10,\n",
      "        sync_cls_avg_factor=True,\n",
      "        type='GroundingDINOHead'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=False,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    decoder=dict(\n",
      "        layer_cfg=dict(\n",
      "            cross_attn_cfg=dict(dropout=0.0, embed_dims=256, num_heads=8),\n",
      "            ffn_cfg=dict(\n",
      "                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0),\n",
      "            self_attn_cfg=dict(dropout=0.0, embed_dims=256, num_heads=8)),\n",
      "        num_layers=6,\n",
      "        post_norm_cfg=None,\n",
      "        return_intermediate=True),\n",
      "    dn_cfg=dict(\n",
      "        box_noise_scale=1.0,\n",
      "        group_cfg=dict(dynamic=True, num_dn_queries=100, num_groups=None),\n",
      "        label_noise_scale=0.5),\n",
      "    encoder=dict(\n",
      "        layer_cfg=dict(\n",
      "            ffn_cfg=dict(\n",
      "                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0),\n",
      "            self_attn_cfg=dict(dropout=0.0, embed_dims=256, num_levels=4)),\n",
      "        num_cp=0,\n",
      "        num_layers=6),\n",
      "    language_model=dict(),\n",
      "    neck=dict(\n",
      "        act_cfg=None,\n",
      "        bias=True,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        kernel_size=1,\n",
      "        norm_cfg=dict(num_groups=32, type='GN'),\n",
      "        num_outs=4,\n",
      "        out_channels=256,\n",
      "        type='ChannelMapper'),\n",
      "    num_queries=900,\n",
      "    positional_encoding=dict(\n",
      "        normalize=True, num_feats=128, offset=0.0, temperature=20),\n",
      "    test_cfg=dict(max_per_img=300),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(\n",
      "            match_costs=[\n",
      "                dict(type='BinaryFocalLossCost', weight=2.0),\n",
      "                dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),\n",
      "                dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "            ],\n",
      "            type='HungarianAssigner')),\n",
      "    type='GroundingDINO',\n",
      "    with_box_refine=True)\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.1, norm_type=2),\n",
      "    optimizer=dict(lr=0.0001, type='AdamW', weight_decay=0.0001),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            backbone=dict(lr_mult=0.1))),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=100,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                800,\n",
      "                1333,\n",
      "            ), type='FixScaleResize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        return_classes=True,\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        800,\n",
      "        1333,\n",
      "    ), type='FixScaleResize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='/data/ephemeral/home/dataset/train_split.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/data/ephemeral/home/dataset/'),\n",
      "        data_root='data/coco/',\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                transforms=[\n",
      "                    [\n",
      "                        dict(\n",
      "                            keep_ratio=True,\n",
      "                            scales=[\n",
      "                                (\n",
      "                                    480,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    512,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    544,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    576,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    608,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    640,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    672,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    704,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    736,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    768,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    800,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                            ],\n",
      "                            type='RandomChoiceResize'),\n",
      "                    ],\n",
      "                    [\n",
      "                        dict(\n",
      "                            keep_ratio=True,\n",
      "                            scales=[\n",
      "                                (\n",
      "                                    400,\n",
      "                                    4200,\n",
      "                                ),\n",
      "                                (\n",
      "                                    500,\n",
      "                                    4200,\n",
      "                                ),\n",
      "                                (\n",
      "                                    600,\n",
      "                                    4200,\n",
      "                                ),\n",
      "                            ],\n",
      "                            type='RandomChoiceResize'),\n",
      "                        dict(\n",
      "                            allow_negative_crop=True,\n",
      "                            crop_size=(\n",
      "                                384,\n",
      "                                600,\n",
      "                            ),\n",
      "                            crop_type='absolute_range',\n",
      "                            type='RandomCrop'),\n",
      "                        dict(\n",
      "                            keep_ratio=True,\n",
      "                            scales=[\n",
      "                                (\n",
      "                                    480,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    512,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    544,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    576,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    608,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    640,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    672,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    704,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    736,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    768,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    800,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                            ],\n",
      "                            type='RandomChoiceResize'),\n",
      "                    ],\n",
      "                ],\n",
      "                type='RandomChoice'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'flip',\n",
      "                    'flip_direction',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        return_classes=True,\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=False,\n",
      "    prefetch_factor=2,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            400,\n",
      "                            4200,\n",
      "                        ),\n",
      "                        (\n",
      "                            500,\n",
      "                            4200,\n",
      "                        ),\n",
      "                        (\n",
      "                            600,\n",
      "                            4200,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "                dict(\n",
      "                    allow_negative_crop=True,\n",
      "                    crop_size=(\n",
      "                        384,\n",
      "                        600,\n",
      "                    ),\n",
      "                    crop_type='absolute_range',\n",
      "                    type='RandomCrop'),\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "        ],\n",
      "        type='RandomChoice'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "            'flip',\n",
      "            'flip_direction',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='/data/ephemeral/home/dataset/val_split.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/data/ephemeral/home/dataset/'),\n",
      "        data_root='data/coco/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                800,\n",
      "                1333,\n",
      "            ), type='FixScaleResize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        return_classes=True,\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=False,\n",
      "    prefetch_factor=2,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='/data/ephemeral/home/dataset/val_split.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='Visualizer',\n",
      "    vis_backends=[\n",
      "        dict(\n",
      "            commit=True,\n",
      "            define_metric_cfg=None,\n",
      "            init_kwargs=dict(\n",
      "                allow_val_change=True,\n",
      "                name=\n",
      "                'grounding_dino_swin-b_finetune_16xb2_1x_coco_20241018_003904',\n",
      "                project='Object_detection'),\n",
      "            log_code_name=None,\n",
      "            save_dir='./work_dirs/co_dino_custom',\n",
      "            type='WandbVisBackend',\n",
      "            watch_kwargs=None),\n",
      "    ])\n",
      "work_dir = './work_dirs/co_dino_custom'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cpuls2el) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grounding_dino_swin-b_finetune_16xb2_1x_coco_20241018_003904</strong> at: <a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/cpuls2el' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection/runs/cpuls2el</a><br/> View project at: <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241018_003904-cpuls2el/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cpuls2el). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./work_dirs/co_dino_custom/wandb/run-20241018_003907-0e8vmb9n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/0e8vmb9n' target=\"_blank\">grounding_dino_swin-b_finetune_16xb2_1x_coco_20241018_003904</a></strong> to <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/0e8vmb9n' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection/runs/0e8vmb9n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "GroundingDinoTransformerEncoder.__init__() missing 2 required positional arguments: 'text_layer_cfg' and 'fusion_layer_cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 설정 파일을 통해 러너 생성\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ---------------------- 레이어 동결 및 Unfreeze 설정 시작 ----------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 2. 모든 레이어를 동결\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnamed_parameters():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:462\u001b[0m, in \u001b[0;36mRunner.from_cfg\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a runner from config.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    Runner: A runner build from ``cfg``.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    461\u001b[0m cfg \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(cfg)\n\u001b[0;32m--> 462\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwork_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_scale_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto_scale_lr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptim_wrapper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_scheduler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_evaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_evaluator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_evaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_evaluator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault_hooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustom_hooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_preprocessor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_from\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlauncher\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menv_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdist_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnccl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_processor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_level\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINFO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisualizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault_scope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmmengine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandomness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiment_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m runner\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:429\u001b[0m, in \u001b[0;36mRunner.__init__\u001b[0;34m(self, model, work_dir, train_dataloader, val_dataloader, test_dataloader, train_cfg, val_cfg, test_cfg, auto_scale_lr, optim_wrapper, param_scheduler, val_evaluator, test_evaluator, default_hooks, custom_hooks, data_preprocessor, load_from, resume, launcher, env_cfg, log_processor, log_level, visualizer, default_scope, randomness, experiment_name, cfg)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m data_preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# Merge the data_preprocessor to model config.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     model\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_preprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, data_preprocessor)\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# wrap model\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_model(\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_wrapper_cfg\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:836\u001b[0m, in \u001b[0;36mRunner.build_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 836\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMODELS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/registry/build_functions.py:232\u001b[0m, in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Sequential(\u001b[38;5;241m*\u001b[39mmodules)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/grounding_dino.py:64\u001b[0m, in \u001b[0;36mGroundingDINO.__init__\u001b[0;34m(self, language_model, use_autocast, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_special_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_autocast \u001b[38;5;241m=\u001b[39m use_autocast\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/dino.py:30\u001b[0m, in \u001b[0;36mDINO.__init__\u001b[0;34m(self, dn_cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, dn_cfg: OptConfigType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_two_stage, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas_two_stage must be True for DINO\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_box_refine, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith_box_refine must be True for DINO\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/deformable_detr.py:69\u001b[0m, in \u001b[0;36mDeformableDETR.__init__\u001b[0;34m(self, decoder, bbox_head, with_box_refine, as_two_stage, num_feature_levels, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     bbox_head[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_pred_layer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (decoder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \\\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_two_stage \u001b[38;5;28;01melse\u001b[39;00m decoder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     67\u001b[0m     bbox_head[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas_two_stage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m as_two_stage\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/base_detr.py:77\u001b[0m, in \u001b[0;36mDetectionTransformer.__init__\u001b[0;34m(self, backbone, neck, encoder, decoder, bbox_head, positional_encoding, num_queries, train_cfg, test_cfg, data_preprocessor, init_cfg)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck \u001b[38;5;241m=\u001b[39m MODELS\u001b[38;5;241m.\u001b[39mbuild(neck)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head \u001b[38;5;241m=\u001b[39m MODELS\u001b[38;5;241m.\u001b[39mbuild(bbox_head)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/grounding_dino.py:70\u001b[0m, in \u001b[0;36mGroundingDINO._init_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize layers except for backbone, neck and bbox_head.\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding \u001b[38;5;241m=\u001b[39m SinePositionalEncoding(\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mGroundingDinoTransformerEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m GroundingDinoTransformerDecoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39membed_dims\n",
      "\u001b[0;31mTypeError\u001b[0m: GroundingDinoTransformerEncoder.__init__() missing 2 required positional arguments: 'text_layer_cfg' and 'fusion_layer_cfg'"
     ]
    }
   ],
   "source": [
    "# 설정 파일을 통해 러너 생성\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "# ---------------------- 레이어 동결 및 Unfreeze 설정 시작 ----------------------\n",
    "\n",
    "# 2. 모든 레이어를 동결\n",
    "for name, param in runner.model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 3. 필요한 레이어 Unfreeze\n",
    "\n",
    "# bbox_head Unfreeze\n",
    "for param in runner.model.bbox_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# backbone의 특정 블록 Unfreeze (stages.3.blocks.0, stages.3.blocks.1)\n",
    "for name, param in runner.model.backbone.named_parameters():\n",
    "    if 'stages.3.blocks.0' in name or 'stages.3.blocks.1' in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "# neck Unfreeze\n",
    "for param in runner.model.neck.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# encoder Unfreeze\n",
    "for param in runner.model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# decoder Unfreeze\n",
    "for param in runner.model.decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# positional_encoding Unfreeze\n",
    "for param in runner.model.positional_encoding.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 7. Optimizer 설정 수정\n",
    "cfg.optim_wrapper.paramwise_cfg = dict(\n",
    "    custom_keys={\n",
    "        'backbone.stages.3.blocks.0': dict(lr_mult=0.1),\n",
    "        'backbone.stages.3.blocks.1': dict(lr_mult=0.1),\n",
    "        'neck': dict(lr_mult=1.0),\n",
    "        'encoder': dict(lr_mult=1.0),\n",
    "        'decoder': dict(lr_mult=1.0),\n",
    "        'positional_encoding': dict(lr_mult=1.0),\n",
    "        'bbox_head': dict(lr_mult=1.0)\n",
    "    }\n",
    ")\n",
    "\n",
    "# ---------------------- 레이어 동결 및 Unfreeze 설정 끝 ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.projection.weight\n",
      "patch_embed.projection.bias\n",
      "patch_embed.norm.weight\n",
      "patch_embed.norm.bias\n",
      "stages.0.blocks.0.norm1.weight\n",
      "stages.0.blocks.0.norm1.bias\n",
      "stages.0.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.0.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.0.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.0.blocks.0.attn.w_msa.proj.weight\n",
      "stages.0.blocks.0.attn.w_msa.proj.bias\n",
      "stages.0.blocks.0.norm2.weight\n",
      "stages.0.blocks.0.norm2.bias\n",
      "stages.0.blocks.0.ffn.layers.0.0.weight\n",
      "stages.0.blocks.0.ffn.layers.0.0.bias\n",
      "stages.0.blocks.0.ffn.layers.1.weight\n",
      "stages.0.blocks.0.ffn.layers.1.bias\n",
      "stages.0.blocks.1.norm1.weight\n",
      "stages.0.blocks.1.norm1.bias\n",
      "stages.0.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.0.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.0.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.0.blocks.1.attn.w_msa.proj.weight\n",
      "stages.0.blocks.1.attn.w_msa.proj.bias\n",
      "stages.0.blocks.1.norm2.weight\n",
      "stages.0.blocks.1.norm2.bias\n",
      "stages.0.blocks.1.ffn.layers.0.0.weight\n",
      "stages.0.blocks.1.ffn.layers.0.0.bias\n",
      "stages.0.blocks.1.ffn.layers.1.weight\n",
      "stages.0.blocks.1.ffn.layers.1.bias\n",
      "stages.0.downsample.norm.weight\n",
      "stages.0.downsample.norm.bias\n",
      "stages.0.downsample.reduction.weight\n",
      "stages.1.blocks.0.norm1.weight\n",
      "stages.1.blocks.0.norm1.bias\n",
      "stages.1.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.1.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.1.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.1.blocks.0.attn.w_msa.proj.weight\n",
      "stages.1.blocks.0.attn.w_msa.proj.bias\n",
      "stages.1.blocks.0.norm2.weight\n",
      "stages.1.blocks.0.norm2.bias\n",
      "stages.1.blocks.0.ffn.layers.0.0.weight\n",
      "stages.1.blocks.0.ffn.layers.0.0.bias\n",
      "stages.1.blocks.0.ffn.layers.1.weight\n",
      "stages.1.blocks.0.ffn.layers.1.bias\n",
      "stages.1.blocks.1.norm1.weight\n",
      "stages.1.blocks.1.norm1.bias\n",
      "stages.1.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.1.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.1.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.1.blocks.1.attn.w_msa.proj.weight\n",
      "stages.1.blocks.1.attn.w_msa.proj.bias\n",
      "stages.1.blocks.1.norm2.weight\n",
      "stages.1.blocks.1.norm2.bias\n",
      "stages.1.blocks.1.ffn.layers.0.0.weight\n",
      "stages.1.blocks.1.ffn.layers.0.0.bias\n",
      "stages.1.blocks.1.ffn.layers.1.weight\n",
      "stages.1.blocks.1.ffn.layers.1.bias\n",
      "stages.1.downsample.norm.weight\n",
      "stages.1.downsample.norm.bias\n",
      "stages.1.downsample.reduction.weight\n",
      "stages.2.blocks.0.norm1.weight\n",
      "stages.2.blocks.0.norm1.bias\n",
      "stages.2.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.0.attn.w_msa.proj.weight\n",
      "stages.2.blocks.0.attn.w_msa.proj.bias\n",
      "stages.2.blocks.0.norm2.weight\n",
      "stages.2.blocks.0.norm2.bias\n",
      "stages.2.blocks.0.ffn.layers.0.0.weight\n",
      "stages.2.blocks.0.ffn.layers.0.0.bias\n",
      "stages.2.blocks.0.ffn.layers.1.weight\n",
      "stages.2.blocks.0.ffn.layers.1.bias\n",
      "stages.2.blocks.1.norm1.weight\n",
      "stages.2.blocks.1.norm1.bias\n",
      "stages.2.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.1.attn.w_msa.proj.weight\n",
      "stages.2.blocks.1.attn.w_msa.proj.bias\n",
      "stages.2.blocks.1.norm2.weight\n",
      "stages.2.blocks.1.norm2.bias\n",
      "stages.2.blocks.1.ffn.layers.0.0.weight\n",
      "stages.2.blocks.1.ffn.layers.0.0.bias\n",
      "stages.2.blocks.1.ffn.layers.1.weight\n",
      "stages.2.blocks.1.ffn.layers.1.bias\n",
      "stages.2.blocks.2.norm1.weight\n",
      "stages.2.blocks.2.norm1.bias\n",
      "stages.2.blocks.2.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.2.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.2.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.2.attn.w_msa.proj.weight\n",
      "stages.2.blocks.2.attn.w_msa.proj.bias\n",
      "stages.2.blocks.2.norm2.weight\n",
      "stages.2.blocks.2.norm2.bias\n",
      "stages.2.blocks.2.ffn.layers.0.0.weight\n",
      "stages.2.blocks.2.ffn.layers.0.0.bias\n",
      "stages.2.blocks.2.ffn.layers.1.weight\n",
      "stages.2.blocks.2.ffn.layers.1.bias\n",
      "stages.2.blocks.3.norm1.weight\n",
      "stages.2.blocks.3.norm1.bias\n",
      "stages.2.blocks.3.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.3.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.3.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.3.attn.w_msa.proj.weight\n",
      "stages.2.blocks.3.attn.w_msa.proj.bias\n",
      "stages.2.blocks.3.norm2.weight\n",
      "stages.2.blocks.3.norm2.bias\n",
      "stages.2.blocks.3.ffn.layers.0.0.weight\n",
      "stages.2.blocks.3.ffn.layers.0.0.bias\n",
      "stages.2.blocks.3.ffn.layers.1.weight\n",
      "stages.2.blocks.3.ffn.layers.1.bias\n",
      "stages.2.blocks.4.norm1.weight\n",
      "stages.2.blocks.4.norm1.bias\n",
      "stages.2.blocks.4.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.4.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.4.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.4.attn.w_msa.proj.weight\n",
      "stages.2.blocks.4.attn.w_msa.proj.bias\n",
      "stages.2.blocks.4.norm2.weight\n",
      "stages.2.blocks.4.norm2.bias\n",
      "stages.2.blocks.4.ffn.layers.0.0.weight\n",
      "stages.2.blocks.4.ffn.layers.0.0.bias\n",
      "stages.2.blocks.4.ffn.layers.1.weight\n",
      "stages.2.blocks.4.ffn.layers.1.bias\n",
      "stages.2.blocks.5.norm1.weight\n",
      "stages.2.blocks.5.norm1.bias\n",
      "stages.2.blocks.5.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.5.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.5.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.5.attn.w_msa.proj.weight\n",
      "stages.2.blocks.5.attn.w_msa.proj.bias\n",
      "stages.2.blocks.5.norm2.weight\n",
      "stages.2.blocks.5.norm2.bias\n",
      "stages.2.blocks.5.ffn.layers.0.0.weight\n",
      "stages.2.blocks.5.ffn.layers.0.0.bias\n",
      "stages.2.blocks.5.ffn.layers.1.weight\n",
      "stages.2.blocks.5.ffn.layers.1.bias\n",
      "stages.2.blocks.6.norm1.weight\n",
      "stages.2.blocks.6.norm1.bias\n",
      "stages.2.blocks.6.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.6.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.6.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.6.attn.w_msa.proj.weight\n",
      "stages.2.blocks.6.attn.w_msa.proj.bias\n",
      "stages.2.blocks.6.norm2.weight\n",
      "stages.2.blocks.6.norm2.bias\n",
      "stages.2.blocks.6.ffn.layers.0.0.weight\n",
      "stages.2.blocks.6.ffn.layers.0.0.bias\n",
      "stages.2.blocks.6.ffn.layers.1.weight\n",
      "stages.2.blocks.6.ffn.layers.1.bias\n",
      "stages.2.blocks.7.norm1.weight\n",
      "stages.2.blocks.7.norm1.bias\n",
      "stages.2.blocks.7.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.7.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.7.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.7.attn.w_msa.proj.weight\n",
      "stages.2.blocks.7.attn.w_msa.proj.bias\n",
      "stages.2.blocks.7.norm2.weight\n",
      "stages.2.blocks.7.norm2.bias\n",
      "stages.2.blocks.7.ffn.layers.0.0.weight\n",
      "stages.2.blocks.7.ffn.layers.0.0.bias\n",
      "stages.2.blocks.7.ffn.layers.1.weight\n",
      "stages.2.blocks.7.ffn.layers.1.bias\n",
      "stages.2.blocks.8.norm1.weight\n",
      "stages.2.blocks.8.norm1.bias\n",
      "stages.2.blocks.8.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.8.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.8.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.8.attn.w_msa.proj.weight\n",
      "stages.2.blocks.8.attn.w_msa.proj.bias\n",
      "stages.2.blocks.8.norm2.weight\n",
      "stages.2.blocks.8.norm2.bias\n",
      "stages.2.blocks.8.ffn.layers.0.0.weight\n",
      "stages.2.blocks.8.ffn.layers.0.0.bias\n",
      "stages.2.blocks.8.ffn.layers.1.weight\n",
      "stages.2.blocks.8.ffn.layers.1.bias\n",
      "stages.2.blocks.9.norm1.weight\n",
      "stages.2.blocks.9.norm1.bias\n",
      "stages.2.blocks.9.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.9.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.9.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.9.attn.w_msa.proj.weight\n",
      "stages.2.blocks.9.attn.w_msa.proj.bias\n",
      "stages.2.blocks.9.norm2.weight\n",
      "stages.2.blocks.9.norm2.bias\n",
      "stages.2.blocks.9.ffn.layers.0.0.weight\n",
      "stages.2.blocks.9.ffn.layers.0.0.bias\n",
      "stages.2.blocks.9.ffn.layers.1.weight\n",
      "stages.2.blocks.9.ffn.layers.1.bias\n",
      "stages.2.blocks.10.norm1.weight\n",
      "stages.2.blocks.10.norm1.bias\n",
      "stages.2.blocks.10.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.10.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.10.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.10.attn.w_msa.proj.weight\n",
      "stages.2.blocks.10.attn.w_msa.proj.bias\n",
      "stages.2.blocks.10.norm2.weight\n",
      "stages.2.blocks.10.norm2.bias\n",
      "stages.2.blocks.10.ffn.layers.0.0.weight\n",
      "stages.2.blocks.10.ffn.layers.0.0.bias\n",
      "stages.2.blocks.10.ffn.layers.1.weight\n",
      "stages.2.blocks.10.ffn.layers.1.bias\n",
      "stages.2.blocks.11.norm1.weight\n",
      "stages.2.blocks.11.norm1.bias\n",
      "stages.2.blocks.11.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.11.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.11.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.11.attn.w_msa.proj.weight\n",
      "stages.2.blocks.11.attn.w_msa.proj.bias\n",
      "stages.2.blocks.11.norm2.weight\n",
      "stages.2.blocks.11.norm2.bias\n",
      "stages.2.blocks.11.ffn.layers.0.0.weight\n",
      "stages.2.blocks.11.ffn.layers.0.0.bias\n",
      "stages.2.blocks.11.ffn.layers.1.weight\n",
      "stages.2.blocks.11.ffn.layers.1.bias\n",
      "stages.2.blocks.12.norm1.weight\n",
      "stages.2.blocks.12.norm1.bias\n",
      "stages.2.blocks.12.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.12.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.12.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.12.attn.w_msa.proj.weight\n",
      "stages.2.blocks.12.attn.w_msa.proj.bias\n",
      "stages.2.blocks.12.norm2.weight\n",
      "stages.2.blocks.12.norm2.bias\n",
      "stages.2.blocks.12.ffn.layers.0.0.weight\n",
      "stages.2.blocks.12.ffn.layers.0.0.bias\n",
      "stages.2.blocks.12.ffn.layers.1.weight\n",
      "stages.2.blocks.12.ffn.layers.1.bias\n",
      "stages.2.blocks.13.norm1.weight\n",
      "stages.2.blocks.13.norm1.bias\n",
      "stages.2.blocks.13.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.13.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.13.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.13.attn.w_msa.proj.weight\n",
      "stages.2.blocks.13.attn.w_msa.proj.bias\n",
      "stages.2.blocks.13.norm2.weight\n",
      "stages.2.blocks.13.norm2.bias\n",
      "stages.2.blocks.13.ffn.layers.0.0.weight\n",
      "stages.2.blocks.13.ffn.layers.0.0.bias\n",
      "stages.2.blocks.13.ffn.layers.1.weight\n",
      "stages.2.blocks.13.ffn.layers.1.bias\n",
      "stages.2.blocks.14.norm1.weight\n",
      "stages.2.blocks.14.norm1.bias\n",
      "stages.2.blocks.14.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.14.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.14.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.14.attn.w_msa.proj.weight\n",
      "stages.2.blocks.14.attn.w_msa.proj.bias\n",
      "stages.2.blocks.14.norm2.weight\n",
      "stages.2.blocks.14.norm2.bias\n",
      "stages.2.blocks.14.ffn.layers.0.0.weight\n",
      "stages.2.blocks.14.ffn.layers.0.0.bias\n",
      "stages.2.blocks.14.ffn.layers.1.weight\n",
      "stages.2.blocks.14.ffn.layers.1.bias\n",
      "stages.2.blocks.15.norm1.weight\n",
      "stages.2.blocks.15.norm1.bias\n",
      "stages.2.blocks.15.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.15.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.15.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.15.attn.w_msa.proj.weight\n",
      "stages.2.blocks.15.attn.w_msa.proj.bias\n",
      "stages.2.blocks.15.norm2.weight\n",
      "stages.2.blocks.15.norm2.bias\n",
      "stages.2.blocks.15.ffn.layers.0.0.weight\n",
      "stages.2.blocks.15.ffn.layers.0.0.bias\n",
      "stages.2.blocks.15.ffn.layers.1.weight\n",
      "stages.2.blocks.15.ffn.layers.1.bias\n",
      "stages.2.blocks.16.norm1.weight\n",
      "stages.2.blocks.16.norm1.bias\n",
      "stages.2.blocks.16.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.16.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.16.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.16.attn.w_msa.proj.weight\n",
      "stages.2.blocks.16.attn.w_msa.proj.bias\n",
      "stages.2.blocks.16.norm2.weight\n",
      "stages.2.blocks.16.norm2.bias\n",
      "stages.2.blocks.16.ffn.layers.0.0.weight\n",
      "stages.2.blocks.16.ffn.layers.0.0.bias\n",
      "stages.2.blocks.16.ffn.layers.1.weight\n",
      "stages.2.blocks.16.ffn.layers.1.bias\n",
      "stages.2.blocks.17.norm1.weight\n",
      "stages.2.blocks.17.norm1.bias\n",
      "stages.2.blocks.17.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.17.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.17.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.17.attn.w_msa.proj.weight\n",
      "stages.2.blocks.17.attn.w_msa.proj.bias\n",
      "stages.2.blocks.17.norm2.weight\n",
      "stages.2.blocks.17.norm2.bias\n",
      "stages.2.blocks.17.ffn.layers.0.0.weight\n",
      "stages.2.blocks.17.ffn.layers.0.0.bias\n",
      "stages.2.blocks.17.ffn.layers.1.weight\n",
      "stages.2.blocks.17.ffn.layers.1.bias\n",
      "stages.2.downsample.norm.weight\n",
      "stages.2.downsample.norm.bias\n",
      "stages.2.downsample.reduction.weight\n",
      "stages.3.blocks.0.norm1.weight\n",
      "stages.3.blocks.0.norm1.bias\n",
      "stages.3.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.3.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.3.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.3.blocks.0.attn.w_msa.proj.weight\n",
      "stages.3.blocks.0.attn.w_msa.proj.bias\n",
      "stages.3.blocks.0.norm2.weight\n",
      "stages.3.blocks.0.norm2.bias\n",
      "stages.3.blocks.0.ffn.layers.0.0.weight\n",
      "stages.3.blocks.0.ffn.layers.0.0.bias\n",
      "stages.3.blocks.0.ffn.layers.1.weight\n",
      "stages.3.blocks.0.ffn.layers.1.bias\n",
      "stages.3.blocks.1.norm1.weight\n",
      "stages.3.blocks.1.norm1.bias\n",
      "stages.3.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.3.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.3.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.3.blocks.1.attn.w_msa.proj.weight\n",
      "stages.3.blocks.1.attn.w_msa.proj.bias\n",
      "stages.3.blocks.1.norm2.weight\n",
      "stages.3.blocks.1.norm2.bias\n",
      "stages.3.blocks.1.ffn.layers.0.0.weight\n",
      "stages.3.blocks.1.ffn.layers.0.0.bias\n",
      "stages.3.blocks.1.ffn.layers.1.weight\n",
      "stages.3.blocks.1.ffn.layers.1.bias\n",
      "norm1.weight\n",
      "norm1.bias\n",
      "norm2.weight\n",
      "norm2.bias\n",
      "norm3.weight\n",
      "norm3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in runner.model.backbone.named_parameters():\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters:\n",
      "backbone.stages.3.blocks.0.norm1.weight\n",
      "backbone.stages.3.blocks.0.norm1.bias\n",
      "backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "backbone.stages.3.blocks.0.attn.w_msa.qkv.weight\n",
      "backbone.stages.3.blocks.0.attn.w_msa.qkv.bias\n",
      "backbone.stages.3.blocks.0.attn.w_msa.proj.weight\n",
      "backbone.stages.3.blocks.0.attn.w_msa.proj.bias\n",
      "backbone.stages.3.blocks.0.norm2.weight\n",
      "backbone.stages.3.blocks.0.norm2.bias\n",
      "backbone.stages.3.blocks.0.ffn.layers.0.0.weight\n",
      "backbone.stages.3.blocks.0.ffn.layers.0.0.bias\n",
      "backbone.stages.3.blocks.0.ffn.layers.1.weight\n",
      "backbone.stages.3.blocks.0.ffn.layers.1.bias\n",
      "backbone.stages.3.blocks.1.norm1.weight\n",
      "backbone.stages.3.blocks.1.norm1.bias\n",
      "backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "backbone.stages.3.blocks.1.attn.w_msa.qkv.weight\n",
      "backbone.stages.3.blocks.1.attn.w_msa.qkv.bias\n",
      "backbone.stages.3.blocks.1.attn.w_msa.proj.weight\n",
      "backbone.stages.3.blocks.1.attn.w_msa.proj.bias\n",
      "backbone.stages.3.blocks.1.norm2.weight\n",
      "backbone.stages.3.blocks.1.norm2.bias\n",
      "backbone.stages.3.blocks.1.ffn.layers.0.0.weight\n",
      "backbone.stages.3.blocks.1.ffn.layers.0.0.bias\n",
      "backbone.stages.3.blocks.1.ffn.layers.1.weight\n",
      "backbone.stages.3.blocks.1.ffn.layers.1.bias\n",
      "neck.convs.0.conv.weight\n",
      "neck.convs.0.conv.bias\n",
      "neck.convs.0.gn.weight\n",
      "neck.convs.0.gn.bias\n",
      "neck.convs.1.conv.weight\n",
      "neck.convs.1.conv.bias\n",
      "neck.convs.1.gn.weight\n",
      "neck.convs.1.gn.bias\n",
      "neck.convs.2.conv.weight\n",
      "neck.convs.2.conv.bias\n",
      "neck.convs.2.gn.weight\n",
      "neck.convs.2.gn.bias\n",
      "neck.extra_convs.0.conv.weight\n",
      "neck.extra_convs.0.conv.bias\n",
      "neck.extra_convs.0.gn.weight\n",
      "neck.extra_convs.0.gn.bias\n",
      "bbox_head.cls_branches.0.log_scale\n",
      "bbox_head.cls_branches.1.log_scale\n",
      "bbox_head.cls_branches.2.log_scale\n",
      "bbox_head.cls_branches.3.log_scale\n",
      "bbox_head.cls_branches.4.log_scale\n",
      "bbox_head.cls_branches.5.log_scale\n",
      "bbox_head.cls_branches.6.log_scale\n",
      "bbox_head.reg_branches.0.0.weight\n",
      "bbox_head.reg_branches.0.0.bias\n",
      "bbox_head.reg_branches.0.2.weight\n",
      "bbox_head.reg_branches.0.2.bias\n",
      "bbox_head.reg_branches.0.4.weight\n",
      "bbox_head.reg_branches.0.4.bias\n",
      "bbox_head.reg_branches.1.0.weight\n",
      "bbox_head.reg_branches.1.0.bias\n",
      "bbox_head.reg_branches.1.2.weight\n",
      "bbox_head.reg_branches.1.2.bias\n",
      "bbox_head.reg_branches.1.4.weight\n",
      "bbox_head.reg_branches.1.4.bias\n",
      "bbox_head.reg_branches.2.0.weight\n",
      "bbox_head.reg_branches.2.0.bias\n",
      "bbox_head.reg_branches.2.2.weight\n",
      "bbox_head.reg_branches.2.2.bias\n",
      "bbox_head.reg_branches.2.4.weight\n",
      "bbox_head.reg_branches.2.4.bias\n",
      "bbox_head.reg_branches.3.0.weight\n",
      "bbox_head.reg_branches.3.0.bias\n",
      "bbox_head.reg_branches.3.2.weight\n",
      "bbox_head.reg_branches.3.2.bias\n",
      "bbox_head.reg_branches.3.4.weight\n",
      "bbox_head.reg_branches.3.4.bias\n",
      "bbox_head.reg_branches.4.0.weight\n",
      "bbox_head.reg_branches.4.0.bias\n",
      "bbox_head.reg_branches.4.2.weight\n",
      "bbox_head.reg_branches.4.2.bias\n",
      "bbox_head.reg_branches.4.4.weight\n",
      "bbox_head.reg_branches.4.4.bias\n",
      "bbox_head.reg_branches.5.0.weight\n",
      "bbox_head.reg_branches.5.0.bias\n",
      "bbox_head.reg_branches.5.2.weight\n",
      "bbox_head.reg_branches.5.2.bias\n",
      "bbox_head.reg_branches.5.4.weight\n",
      "bbox_head.reg_branches.5.4.bias\n",
      "bbox_head.reg_branches.6.0.weight\n",
      "bbox_head.reg_branches.6.0.bias\n",
      "bbox_head.reg_branches.6.2.weight\n",
      "bbox_head.reg_branches.6.2.bias\n",
      "bbox_head.reg_branches.6.4.weight\n",
      "bbox_head.reg_branches.6.4.bias\n",
      "encoder.layers.0.self_attn.sampling_offsets.weight\n",
      "encoder.layers.0.self_attn.sampling_offsets.bias\n",
      "encoder.layers.0.self_attn.attention_weights.weight\n",
      "encoder.layers.0.self_attn.attention_weights.bias\n",
      "encoder.layers.0.self_attn.value_proj.weight\n",
      "encoder.layers.0.self_attn.value_proj.bias\n",
      "encoder.layers.0.self_attn.output_proj.weight\n",
      "encoder.layers.0.self_attn.output_proj.bias\n",
      "encoder.layers.0.ffn.layers.0.0.weight\n",
      "encoder.layers.0.ffn.layers.0.0.bias\n",
      "encoder.layers.0.ffn.layers.1.weight\n",
      "encoder.layers.0.ffn.layers.1.bias\n",
      "encoder.layers.0.norms.0.weight\n",
      "encoder.layers.0.norms.0.bias\n",
      "encoder.layers.0.norms.1.weight\n",
      "encoder.layers.0.norms.1.bias\n",
      "encoder.layers.1.self_attn.sampling_offsets.weight\n",
      "encoder.layers.1.self_attn.sampling_offsets.bias\n",
      "encoder.layers.1.self_attn.attention_weights.weight\n",
      "encoder.layers.1.self_attn.attention_weights.bias\n",
      "encoder.layers.1.self_attn.value_proj.weight\n",
      "encoder.layers.1.self_attn.value_proj.bias\n",
      "encoder.layers.1.self_attn.output_proj.weight\n",
      "encoder.layers.1.self_attn.output_proj.bias\n",
      "encoder.layers.1.ffn.layers.0.0.weight\n",
      "encoder.layers.1.ffn.layers.0.0.bias\n",
      "encoder.layers.1.ffn.layers.1.weight\n",
      "encoder.layers.1.ffn.layers.1.bias\n",
      "encoder.layers.1.norms.0.weight\n",
      "encoder.layers.1.norms.0.bias\n",
      "encoder.layers.1.norms.1.weight\n",
      "encoder.layers.1.norms.1.bias\n",
      "encoder.layers.2.self_attn.sampling_offsets.weight\n",
      "encoder.layers.2.self_attn.sampling_offsets.bias\n",
      "encoder.layers.2.self_attn.attention_weights.weight\n",
      "encoder.layers.2.self_attn.attention_weights.bias\n",
      "encoder.layers.2.self_attn.value_proj.weight\n",
      "encoder.layers.2.self_attn.value_proj.bias\n",
      "encoder.layers.2.self_attn.output_proj.weight\n",
      "encoder.layers.2.self_attn.output_proj.bias\n",
      "encoder.layers.2.ffn.layers.0.0.weight\n",
      "encoder.layers.2.ffn.layers.0.0.bias\n",
      "encoder.layers.2.ffn.layers.1.weight\n",
      "encoder.layers.2.ffn.layers.1.bias\n",
      "encoder.layers.2.norms.0.weight\n",
      "encoder.layers.2.norms.0.bias\n",
      "encoder.layers.2.norms.1.weight\n",
      "encoder.layers.2.norms.1.bias\n",
      "encoder.layers.3.self_attn.sampling_offsets.weight\n",
      "encoder.layers.3.self_attn.sampling_offsets.bias\n",
      "encoder.layers.3.self_attn.attention_weights.weight\n",
      "encoder.layers.3.self_attn.attention_weights.bias\n",
      "encoder.layers.3.self_attn.value_proj.weight\n",
      "encoder.layers.3.self_attn.value_proj.bias\n",
      "encoder.layers.3.self_attn.output_proj.weight\n",
      "encoder.layers.3.self_attn.output_proj.bias\n",
      "encoder.layers.3.ffn.layers.0.0.weight\n",
      "encoder.layers.3.ffn.layers.0.0.bias\n",
      "encoder.layers.3.ffn.layers.1.weight\n",
      "encoder.layers.3.ffn.layers.1.bias\n",
      "encoder.layers.3.norms.0.weight\n",
      "encoder.layers.3.norms.0.bias\n",
      "encoder.layers.3.norms.1.weight\n",
      "encoder.layers.3.norms.1.bias\n",
      "encoder.layers.4.self_attn.sampling_offsets.weight\n",
      "encoder.layers.4.self_attn.sampling_offsets.bias\n",
      "encoder.layers.4.self_attn.attention_weights.weight\n",
      "encoder.layers.4.self_attn.attention_weights.bias\n",
      "encoder.layers.4.self_attn.value_proj.weight\n",
      "encoder.layers.4.self_attn.value_proj.bias\n",
      "encoder.layers.4.self_attn.output_proj.weight\n",
      "encoder.layers.4.self_attn.output_proj.bias\n",
      "encoder.layers.4.ffn.layers.0.0.weight\n",
      "encoder.layers.4.ffn.layers.0.0.bias\n",
      "encoder.layers.4.ffn.layers.1.weight\n",
      "encoder.layers.4.ffn.layers.1.bias\n",
      "encoder.layers.4.norms.0.weight\n",
      "encoder.layers.4.norms.0.bias\n",
      "encoder.layers.4.norms.1.weight\n",
      "encoder.layers.4.norms.1.bias\n",
      "encoder.layers.5.self_attn.sampling_offsets.weight\n",
      "encoder.layers.5.self_attn.sampling_offsets.bias\n",
      "encoder.layers.5.self_attn.attention_weights.weight\n",
      "encoder.layers.5.self_attn.attention_weights.bias\n",
      "encoder.layers.5.self_attn.value_proj.weight\n",
      "encoder.layers.5.self_attn.value_proj.bias\n",
      "encoder.layers.5.self_attn.output_proj.weight\n",
      "encoder.layers.5.self_attn.output_proj.bias\n",
      "encoder.layers.5.ffn.layers.0.0.weight\n",
      "encoder.layers.5.ffn.layers.0.0.bias\n",
      "encoder.layers.5.ffn.layers.1.weight\n",
      "encoder.layers.5.ffn.layers.1.bias\n",
      "encoder.layers.5.norms.0.weight\n",
      "encoder.layers.5.norms.0.bias\n",
      "encoder.layers.5.norms.1.weight\n",
      "encoder.layers.5.norms.1.bias\n",
      "encoder.text_layers.0.self_attn.attn.in_proj_weight\n",
      "encoder.text_layers.0.self_attn.attn.in_proj_bias\n",
      "encoder.text_layers.0.self_attn.attn.out_proj.weight\n",
      "encoder.text_layers.0.self_attn.attn.out_proj.bias\n",
      "encoder.text_layers.0.ffn.layers.0.0.weight\n",
      "encoder.text_layers.0.ffn.layers.0.0.bias\n",
      "encoder.text_layers.0.ffn.layers.1.weight\n",
      "encoder.text_layers.0.ffn.layers.1.bias\n",
      "encoder.text_layers.0.norms.0.weight\n",
      "encoder.text_layers.0.norms.0.bias\n",
      "encoder.text_layers.0.norms.1.weight\n",
      "encoder.text_layers.0.norms.1.bias\n",
      "encoder.text_layers.1.self_attn.attn.in_proj_weight\n",
      "encoder.text_layers.1.self_attn.attn.in_proj_bias\n",
      "encoder.text_layers.1.self_attn.attn.out_proj.weight\n",
      "encoder.text_layers.1.self_attn.attn.out_proj.bias\n",
      "encoder.text_layers.1.ffn.layers.0.0.weight\n",
      "encoder.text_layers.1.ffn.layers.0.0.bias\n",
      "encoder.text_layers.1.ffn.layers.1.weight\n",
      "encoder.text_layers.1.ffn.layers.1.bias\n",
      "encoder.text_layers.1.norms.0.weight\n",
      "encoder.text_layers.1.norms.0.bias\n",
      "encoder.text_layers.1.norms.1.weight\n",
      "encoder.text_layers.1.norms.1.bias\n",
      "encoder.text_layers.2.self_attn.attn.in_proj_weight\n",
      "encoder.text_layers.2.self_attn.attn.in_proj_bias\n",
      "encoder.text_layers.2.self_attn.attn.out_proj.weight\n",
      "encoder.text_layers.2.self_attn.attn.out_proj.bias\n",
      "encoder.text_layers.2.ffn.layers.0.0.weight\n",
      "encoder.text_layers.2.ffn.layers.0.0.bias\n",
      "encoder.text_layers.2.ffn.layers.1.weight\n",
      "encoder.text_layers.2.ffn.layers.1.bias\n",
      "encoder.text_layers.2.norms.0.weight\n",
      "encoder.text_layers.2.norms.0.bias\n",
      "encoder.text_layers.2.norms.1.weight\n",
      "encoder.text_layers.2.norms.1.bias\n",
      "encoder.text_layers.3.self_attn.attn.in_proj_weight\n",
      "encoder.text_layers.3.self_attn.attn.in_proj_bias\n",
      "encoder.text_layers.3.self_attn.attn.out_proj.weight\n",
      "encoder.text_layers.3.self_attn.attn.out_proj.bias\n",
      "encoder.text_layers.3.ffn.layers.0.0.weight\n",
      "encoder.text_layers.3.ffn.layers.0.0.bias\n",
      "encoder.text_layers.3.ffn.layers.1.weight\n",
      "encoder.text_layers.3.ffn.layers.1.bias\n",
      "encoder.text_layers.3.norms.0.weight\n",
      "encoder.text_layers.3.norms.0.bias\n",
      "encoder.text_layers.3.norms.1.weight\n",
      "encoder.text_layers.3.norms.1.bias\n",
      "encoder.text_layers.4.self_attn.attn.in_proj_weight\n",
      "encoder.text_layers.4.self_attn.attn.in_proj_bias\n",
      "encoder.text_layers.4.self_attn.attn.out_proj.weight\n",
      "encoder.text_layers.4.self_attn.attn.out_proj.bias\n",
      "encoder.text_layers.4.ffn.layers.0.0.weight\n",
      "encoder.text_layers.4.ffn.layers.0.0.bias\n",
      "encoder.text_layers.4.ffn.layers.1.weight\n",
      "encoder.text_layers.4.ffn.layers.1.bias\n",
      "encoder.text_layers.4.norms.0.weight\n",
      "encoder.text_layers.4.norms.0.bias\n",
      "encoder.text_layers.4.norms.1.weight\n",
      "encoder.text_layers.4.norms.1.bias\n",
      "encoder.text_layers.5.self_attn.attn.in_proj_weight\n",
      "encoder.text_layers.5.self_attn.attn.in_proj_bias\n",
      "encoder.text_layers.5.self_attn.attn.out_proj.weight\n",
      "encoder.text_layers.5.self_attn.attn.out_proj.bias\n",
      "encoder.text_layers.5.ffn.layers.0.0.weight\n",
      "encoder.text_layers.5.ffn.layers.0.0.bias\n",
      "encoder.text_layers.5.ffn.layers.1.weight\n",
      "encoder.text_layers.5.ffn.layers.1.bias\n",
      "encoder.text_layers.5.norms.0.weight\n",
      "encoder.text_layers.5.norms.0.bias\n",
      "encoder.text_layers.5.norms.1.weight\n",
      "encoder.text_layers.5.norms.1.bias\n",
      "encoder.fusion_layers.0.gamma_v\n",
      "encoder.fusion_layers.0.gamma_l\n",
      "encoder.fusion_layers.0.layer_norm_v.weight\n",
      "encoder.fusion_layers.0.layer_norm_v.bias\n",
      "encoder.fusion_layers.0.layer_norm_l.weight\n",
      "encoder.fusion_layers.0.layer_norm_l.bias\n",
      "encoder.fusion_layers.0.attn.v_proj.weight\n",
      "encoder.fusion_layers.0.attn.v_proj.bias\n",
      "encoder.fusion_layers.0.attn.l_proj.weight\n",
      "encoder.fusion_layers.0.attn.l_proj.bias\n",
      "encoder.fusion_layers.0.attn.values_v_proj.weight\n",
      "encoder.fusion_layers.0.attn.values_v_proj.bias\n",
      "encoder.fusion_layers.0.attn.values_l_proj.weight\n",
      "encoder.fusion_layers.0.attn.values_l_proj.bias\n",
      "encoder.fusion_layers.0.attn.out_v_proj.weight\n",
      "encoder.fusion_layers.0.attn.out_v_proj.bias\n",
      "encoder.fusion_layers.0.attn.out_l_proj.weight\n",
      "encoder.fusion_layers.0.attn.out_l_proj.bias\n",
      "encoder.fusion_layers.1.gamma_v\n",
      "encoder.fusion_layers.1.gamma_l\n",
      "encoder.fusion_layers.1.layer_norm_v.weight\n",
      "encoder.fusion_layers.1.layer_norm_v.bias\n",
      "encoder.fusion_layers.1.layer_norm_l.weight\n",
      "encoder.fusion_layers.1.layer_norm_l.bias\n",
      "encoder.fusion_layers.1.attn.v_proj.weight\n",
      "encoder.fusion_layers.1.attn.v_proj.bias\n",
      "encoder.fusion_layers.1.attn.l_proj.weight\n",
      "encoder.fusion_layers.1.attn.l_proj.bias\n",
      "encoder.fusion_layers.1.attn.values_v_proj.weight\n",
      "encoder.fusion_layers.1.attn.values_v_proj.bias\n",
      "encoder.fusion_layers.1.attn.values_l_proj.weight\n",
      "encoder.fusion_layers.1.attn.values_l_proj.bias\n",
      "encoder.fusion_layers.1.attn.out_v_proj.weight\n",
      "encoder.fusion_layers.1.attn.out_v_proj.bias\n",
      "encoder.fusion_layers.1.attn.out_l_proj.weight\n",
      "encoder.fusion_layers.1.attn.out_l_proj.bias\n",
      "encoder.fusion_layers.2.gamma_v\n",
      "encoder.fusion_layers.2.gamma_l\n",
      "encoder.fusion_layers.2.layer_norm_v.weight\n",
      "encoder.fusion_layers.2.layer_norm_v.bias\n",
      "encoder.fusion_layers.2.layer_norm_l.weight\n",
      "encoder.fusion_layers.2.layer_norm_l.bias\n",
      "encoder.fusion_layers.2.attn.v_proj.weight\n",
      "encoder.fusion_layers.2.attn.v_proj.bias\n",
      "encoder.fusion_layers.2.attn.l_proj.weight\n",
      "encoder.fusion_layers.2.attn.l_proj.bias\n",
      "encoder.fusion_layers.2.attn.values_v_proj.weight\n",
      "encoder.fusion_layers.2.attn.values_v_proj.bias\n",
      "encoder.fusion_layers.2.attn.values_l_proj.weight\n",
      "encoder.fusion_layers.2.attn.values_l_proj.bias\n",
      "encoder.fusion_layers.2.attn.out_v_proj.weight\n",
      "encoder.fusion_layers.2.attn.out_v_proj.bias\n",
      "encoder.fusion_layers.2.attn.out_l_proj.weight\n",
      "encoder.fusion_layers.2.attn.out_l_proj.bias\n",
      "encoder.fusion_layers.3.gamma_v\n",
      "encoder.fusion_layers.3.gamma_l\n",
      "encoder.fusion_layers.3.layer_norm_v.weight\n",
      "encoder.fusion_layers.3.layer_norm_v.bias\n",
      "encoder.fusion_layers.3.layer_norm_l.weight\n",
      "encoder.fusion_layers.3.layer_norm_l.bias\n",
      "encoder.fusion_layers.3.attn.v_proj.weight\n",
      "encoder.fusion_layers.3.attn.v_proj.bias\n",
      "encoder.fusion_layers.3.attn.l_proj.weight\n",
      "encoder.fusion_layers.3.attn.l_proj.bias\n",
      "encoder.fusion_layers.3.attn.values_v_proj.weight\n",
      "encoder.fusion_layers.3.attn.values_v_proj.bias\n",
      "encoder.fusion_layers.3.attn.values_l_proj.weight\n",
      "encoder.fusion_layers.3.attn.values_l_proj.bias\n",
      "encoder.fusion_layers.3.attn.out_v_proj.weight\n",
      "encoder.fusion_layers.3.attn.out_v_proj.bias\n",
      "encoder.fusion_layers.3.attn.out_l_proj.weight\n",
      "encoder.fusion_layers.3.attn.out_l_proj.bias\n",
      "encoder.fusion_layers.4.gamma_v\n",
      "encoder.fusion_layers.4.gamma_l\n",
      "encoder.fusion_layers.4.layer_norm_v.weight\n",
      "encoder.fusion_layers.4.layer_norm_v.bias\n",
      "encoder.fusion_layers.4.layer_norm_l.weight\n",
      "encoder.fusion_layers.4.layer_norm_l.bias\n",
      "encoder.fusion_layers.4.attn.v_proj.weight\n",
      "encoder.fusion_layers.4.attn.v_proj.bias\n",
      "encoder.fusion_layers.4.attn.l_proj.weight\n",
      "encoder.fusion_layers.4.attn.l_proj.bias\n",
      "encoder.fusion_layers.4.attn.values_v_proj.weight\n",
      "encoder.fusion_layers.4.attn.values_v_proj.bias\n",
      "encoder.fusion_layers.4.attn.values_l_proj.weight\n",
      "encoder.fusion_layers.4.attn.values_l_proj.bias\n",
      "encoder.fusion_layers.4.attn.out_v_proj.weight\n",
      "encoder.fusion_layers.4.attn.out_v_proj.bias\n",
      "encoder.fusion_layers.4.attn.out_l_proj.weight\n",
      "encoder.fusion_layers.4.attn.out_l_proj.bias\n",
      "encoder.fusion_layers.5.gamma_v\n",
      "encoder.fusion_layers.5.gamma_l\n",
      "encoder.fusion_layers.5.layer_norm_v.weight\n",
      "encoder.fusion_layers.5.layer_norm_v.bias\n",
      "encoder.fusion_layers.5.layer_norm_l.weight\n",
      "encoder.fusion_layers.5.layer_norm_l.bias\n",
      "encoder.fusion_layers.5.attn.v_proj.weight\n",
      "encoder.fusion_layers.5.attn.v_proj.bias\n",
      "encoder.fusion_layers.5.attn.l_proj.weight\n",
      "encoder.fusion_layers.5.attn.l_proj.bias\n",
      "encoder.fusion_layers.5.attn.values_v_proj.weight\n",
      "encoder.fusion_layers.5.attn.values_v_proj.bias\n",
      "encoder.fusion_layers.5.attn.values_l_proj.weight\n",
      "encoder.fusion_layers.5.attn.values_l_proj.bias\n",
      "encoder.fusion_layers.5.attn.out_v_proj.weight\n",
      "encoder.fusion_layers.5.attn.out_v_proj.bias\n",
      "encoder.fusion_layers.5.attn.out_l_proj.weight\n",
      "encoder.fusion_layers.5.attn.out_l_proj.bias\n",
      "decoder.layers.0.self_attn.attn.in_proj_weight\n",
      "decoder.layers.0.self_attn.attn.in_proj_bias\n",
      "decoder.layers.0.self_attn.attn.out_proj.weight\n",
      "decoder.layers.0.self_attn.attn.out_proj.bias\n",
      "decoder.layers.0.cross_attn_text.attn.in_proj_weight\n",
      "decoder.layers.0.cross_attn_text.attn.in_proj_bias\n",
      "decoder.layers.0.cross_attn_text.attn.out_proj.weight\n",
      "decoder.layers.0.cross_attn_text.attn.out_proj.bias\n",
      "decoder.layers.0.cross_attn.sampling_offsets.weight\n",
      "decoder.layers.0.cross_attn.sampling_offsets.bias\n",
      "decoder.layers.0.cross_attn.attention_weights.weight\n",
      "decoder.layers.0.cross_attn.attention_weights.bias\n",
      "decoder.layers.0.cross_attn.value_proj.weight\n",
      "decoder.layers.0.cross_attn.value_proj.bias\n",
      "decoder.layers.0.cross_attn.output_proj.weight\n",
      "decoder.layers.0.cross_attn.output_proj.bias\n",
      "decoder.layers.0.ffn.layers.0.0.weight\n",
      "decoder.layers.0.ffn.layers.0.0.bias\n",
      "decoder.layers.0.ffn.layers.1.weight\n",
      "decoder.layers.0.ffn.layers.1.bias\n",
      "decoder.layers.0.norms.0.weight\n",
      "decoder.layers.0.norms.0.bias\n",
      "decoder.layers.0.norms.1.weight\n",
      "decoder.layers.0.norms.1.bias\n",
      "decoder.layers.0.norms.2.weight\n",
      "decoder.layers.0.norms.2.bias\n",
      "decoder.layers.0.norms.3.weight\n",
      "decoder.layers.0.norms.3.bias\n",
      "decoder.layers.1.self_attn.attn.in_proj_weight\n",
      "decoder.layers.1.self_attn.attn.in_proj_bias\n",
      "decoder.layers.1.self_attn.attn.out_proj.weight\n",
      "decoder.layers.1.self_attn.attn.out_proj.bias\n",
      "decoder.layers.1.cross_attn_text.attn.in_proj_weight\n",
      "decoder.layers.1.cross_attn_text.attn.in_proj_bias\n",
      "decoder.layers.1.cross_attn_text.attn.out_proj.weight\n",
      "decoder.layers.1.cross_attn_text.attn.out_proj.bias\n",
      "decoder.layers.1.cross_attn.sampling_offsets.weight\n",
      "decoder.layers.1.cross_attn.sampling_offsets.bias\n",
      "decoder.layers.1.cross_attn.attention_weights.weight\n",
      "decoder.layers.1.cross_attn.attention_weights.bias\n",
      "decoder.layers.1.cross_attn.value_proj.weight\n",
      "decoder.layers.1.cross_attn.value_proj.bias\n",
      "decoder.layers.1.cross_attn.output_proj.weight\n",
      "decoder.layers.1.cross_attn.output_proj.bias\n",
      "decoder.layers.1.ffn.layers.0.0.weight\n",
      "decoder.layers.1.ffn.layers.0.0.bias\n",
      "decoder.layers.1.ffn.layers.1.weight\n",
      "decoder.layers.1.ffn.layers.1.bias\n",
      "decoder.layers.1.norms.0.weight\n",
      "decoder.layers.1.norms.0.bias\n",
      "decoder.layers.1.norms.1.weight\n",
      "decoder.layers.1.norms.1.bias\n",
      "decoder.layers.1.norms.2.weight\n",
      "decoder.layers.1.norms.2.bias\n",
      "decoder.layers.1.norms.3.weight\n",
      "decoder.layers.1.norms.3.bias\n",
      "decoder.layers.2.self_attn.attn.in_proj_weight\n",
      "decoder.layers.2.self_attn.attn.in_proj_bias\n",
      "decoder.layers.2.self_attn.attn.out_proj.weight\n",
      "decoder.layers.2.self_attn.attn.out_proj.bias\n",
      "decoder.layers.2.cross_attn_text.attn.in_proj_weight\n",
      "decoder.layers.2.cross_attn_text.attn.in_proj_bias\n",
      "decoder.layers.2.cross_attn_text.attn.out_proj.weight\n",
      "decoder.layers.2.cross_attn_text.attn.out_proj.bias\n",
      "decoder.layers.2.cross_attn.sampling_offsets.weight\n",
      "decoder.layers.2.cross_attn.sampling_offsets.bias\n",
      "decoder.layers.2.cross_attn.attention_weights.weight\n",
      "decoder.layers.2.cross_attn.attention_weights.bias\n",
      "decoder.layers.2.cross_attn.value_proj.weight\n",
      "decoder.layers.2.cross_attn.value_proj.bias\n",
      "decoder.layers.2.cross_attn.output_proj.weight\n",
      "decoder.layers.2.cross_attn.output_proj.bias\n",
      "decoder.layers.2.ffn.layers.0.0.weight\n",
      "decoder.layers.2.ffn.layers.0.0.bias\n",
      "decoder.layers.2.ffn.layers.1.weight\n",
      "decoder.layers.2.ffn.layers.1.bias\n",
      "decoder.layers.2.norms.0.weight\n",
      "decoder.layers.2.norms.0.bias\n",
      "decoder.layers.2.norms.1.weight\n",
      "decoder.layers.2.norms.1.bias\n",
      "decoder.layers.2.norms.2.weight\n",
      "decoder.layers.2.norms.2.bias\n",
      "decoder.layers.2.norms.3.weight\n",
      "decoder.layers.2.norms.3.bias\n",
      "decoder.layers.3.self_attn.attn.in_proj_weight\n",
      "decoder.layers.3.self_attn.attn.in_proj_bias\n",
      "decoder.layers.3.self_attn.attn.out_proj.weight\n",
      "decoder.layers.3.self_attn.attn.out_proj.bias\n",
      "decoder.layers.3.cross_attn_text.attn.in_proj_weight\n",
      "decoder.layers.3.cross_attn_text.attn.in_proj_bias\n",
      "decoder.layers.3.cross_attn_text.attn.out_proj.weight\n",
      "decoder.layers.3.cross_attn_text.attn.out_proj.bias\n",
      "decoder.layers.3.cross_attn.sampling_offsets.weight\n",
      "decoder.layers.3.cross_attn.sampling_offsets.bias\n",
      "decoder.layers.3.cross_attn.attention_weights.weight\n",
      "decoder.layers.3.cross_attn.attention_weights.bias\n",
      "decoder.layers.3.cross_attn.value_proj.weight\n",
      "decoder.layers.3.cross_attn.value_proj.bias\n",
      "decoder.layers.3.cross_attn.output_proj.weight\n",
      "decoder.layers.3.cross_attn.output_proj.bias\n",
      "decoder.layers.3.ffn.layers.0.0.weight\n",
      "decoder.layers.3.ffn.layers.0.0.bias\n",
      "decoder.layers.3.ffn.layers.1.weight\n",
      "decoder.layers.3.ffn.layers.1.bias\n",
      "decoder.layers.3.norms.0.weight\n",
      "decoder.layers.3.norms.0.bias\n",
      "decoder.layers.3.norms.1.weight\n",
      "decoder.layers.3.norms.1.bias\n",
      "decoder.layers.3.norms.2.weight\n",
      "decoder.layers.3.norms.2.bias\n",
      "decoder.layers.3.norms.3.weight\n",
      "decoder.layers.3.norms.3.bias\n",
      "decoder.layers.4.self_attn.attn.in_proj_weight\n",
      "decoder.layers.4.self_attn.attn.in_proj_bias\n",
      "decoder.layers.4.self_attn.attn.out_proj.weight\n",
      "decoder.layers.4.self_attn.attn.out_proj.bias\n",
      "decoder.layers.4.cross_attn_text.attn.in_proj_weight\n",
      "decoder.layers.4.cross_attn_text.attn.in_proj_bias\n",
      "decoder.layers.4.cross_attn_text.attn.out_proj.weight\n",
      "decoder.layers.4.cross_attn_text.attn.out_proj.bias\n",
      "decoder.layers.4.cross_attn.sampling_offsets.weight\n",
      "decoder.layers.4.cross_attn.sampling_offsets.bias\n",
      "decoder.layers.4.cross_attn.attention_weights.weight\n",
      "decoder.layers.4.cross_attn.attention_weights.bias\n",
      "decoder.layers.4.cross_attn.value_proj.weight\n",
      "decoder.layers.4.cross_attn.value_proj.bias\n",
      "decoder.layers.4.cross_attn.output_proj.weight\n",
      "decoder.layers.4.cross_attn.output_proj.bias\n",
      "decoder.layers.4.ffn.layers.0.0.weight\n",
      "decoder.layers.4.ffn.layers.0.0.bias\n",
      "decoder.layers.4.ffn.layers.1.weight\n",
      "decoder.layers.4.ffn.layers.1.bias\n",
      "decoder.layers.4.norms.0.weight\n",
      "decoder.layers.4.norms.0.bias\n",
      "decoder.layers.4.norms.1.weight\n",
      "decoder.layers.4.norms.1.bias\n",
      "decoder.layers.4.norms.2.weight\n",
      "decoder.layers.4.norms.2.bias\n",
      "decoder.layers.4.norms.3.weight\n",
      "decoder.layers.4.norms.3.bias\n",
      "decoder.layers.5.self_attn.attn.in_proj_weight\n",
      "decoder.layers.5.self_attn.attn.in_proj_bias\n",
      "decoder.layers.5.self_attn.attn.out_proj.weight\n",
      "decoder.layers.5.self_attn.attn.out_proj.bias\n",
      "decoder.layers.5.cross_attn_text.attn.in_proj_weight\n",
      "decoder.layers.5.cross_attn_text.attn.in_proj_bias\n",
      "decoder.layers.5.cross_attn_text.attn.out_proj.weight\n",
      "decoder.layers.5.cross_attn_text.attn.out_proj.bias\n",
      "decoder.layers.5.cross_attn.sampling_offsets.weight\n",
      "decoder.layers.5.cross_attn.sampling_offsets.bias\n",
      "decoder.layers.5.cross_attn.attention_weights.weight\n",
      "decoder.layers.5.cross_attn.attention_weights.bias\n",
      "decoder.layers.5.cross_attn.value_proj.weight\n",
      "decoder.layers.5.cross_attn.value_proj.bias\n",
      "decoder.layers.5.cross_attn.output_proj.weight\n",
      "decoder.layers.5.cross_attn.output_proj.bias\n",
      "decoder.layers.5.ffn.layers.0.0.weight\n",
      "decoder.layers.5.ffn.layers.0.0.bias\n",
      "decoder.layers.5.ffn.layers.1.weight\n",
      "decoder.layers.5.ffn.layers.1.bias\n",
      "decoder.layers.5.norms.0.weight\n",
      "decoder.layers.5.norms.0.bias\n",
      "decoder.layers.5.norms.1.weight\n",
      "decoder.layers.5.norms.1.bias\n",
      "decoder.layers.5.norms.2.weight\n",
      "decoder.layers.5.norms.2.bias\n",
      "decoder.layers.5.norms.3.weight\n",
      "decoder.layers.5.norms.3.bias\n",
      "decoder.ref_point_head.layers.0.weight\n",
      "decoder.ref_point_head.layers.0.bias\n",
      "decoder.ref_point_head.layers.1.weight\n",
      "decoder.ref_point_head.layers.1.bias\n",
      "decoder.norm.weight\n",
      "decoder.norm.bias\n"
     ]
    }
   ],
   "source": [
    "# 학습 가능한 파라미터 출력 (디버깅 용도)\n",
    "trainable_params = [name for name, param in runner.model.named_parameters() if param.requires_grad]\n",
    "print(\"Trainable parameters:\")\n",
    "for name in trainable_params:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.0001\n",
      "10/17 23:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "10/17 23:50:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - No pre-trained weights for SwinTransformer, training start from scratch\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/grounding_dino/groundingdino_swinb_cogcoor_mmdet-55949c9c.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: language_model.language_backbone.body.model.pooler.dense.weight, language_model.language_backbone.body.model.pooler.dense.bias, language_model.language_backbone.body.model.embeddings.position_ids\n",
      "\n",
      "missing keys in source state_dict: bbox_head.cls_branches.0.log_scale, bbox_head.cls_branches.1.log_scale, bbox_head.cls_branches.2.log_scale, bbox_head.cls_branches.3.log_scale, bbox_head.cls_branches.4.log_scale, bbox_head.cls_branches.5.log_scale, bbox_head.cls_branches.6.log_scale, dn_query_generator.label_embedding.weight\n",
      "\n",
      "10/17 23:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmdetection/v3.0/grounding_dino/groundingdino_swinb_cogcoor_mmdet-55949c9c.pth\n",
      "10/17 23:50:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "10/17 23:50:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "10/17 23:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /data/ephemeral/home/baseline/mmdetection/work_dirs/co_dino_custom.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/layers/positional_encoding.py:103: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/layers/transformer/utils.py:71: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = temperature**(2 * (dim_t // 2) / num_feats)\n",
      "/opt/conda/lib/python3.10/site-packages/mmcv/cnn/bricks/transformer.py:524: UserWarning: position encoding of key ismissing in MultiheadAttention.\n",
      "  warnings.warn(f'position encoding of key is'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/17 23:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 50/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:37:39  time: 1.1118  data_time: 0.0151  memory: 20773  grad_norm: 59.1553  loss: 16.2263  loss_cls: 0.7361  loss_bbox: 0.1572  loss_iou: 0.2117  d0.loss_cls: 0.7060  d0.loss_bbox: 0.1868  d0.loss_iou: 0.2441  d1.loss_cls: 0.7086  d1.loss_bbox: 0.1775  d1.loss_iou: 0.2328  d2.loss_cls: 0.7350  d2.loss_bbox: 0.1646  d2.loss_iou: 0.2190  d3.loss_cls: 0.7374  d3.loss_bbox: 0.1623  d3.loss_iou: 0.2150  d4.loss_cls: 0.7440  d4.loss_bbox: 0.1577  d4.loss_iou: 0.2115  enc_loss_cls: 0.7321  enc_loss_bbox: 0.2022  enc_loss_iou: 0.2668  dn_loss_cls: 0.5564  dn_loss_bbox: 0.3820  dn_loss_iou: 0.3702  d0.dn_loss_cls: 0.5924  d0.dn_loss_bbox: 0.5270  d0.dn_loss_iou: 0.5105  d1.dn_loss_cls: 0.5710  d1.dn_loss_bbox: 0.4040  d1.dn_loss_iou: 0.4076  d2.dn_loss_cls: 0.5603  d2.dn_loss_bbox: 0.3917  d2.dn_loss_iou: 0.3823  d3.dn_loss_cls: 0.5555  d3.dn_loss_bbox: 0.4029  d3.dn_loss_iou: 0.3857  d4.dn_loss_cls: 0.5575  d4.dn_loss_bbox: 0.3876  d4.dn_loss_iou: 0.3735\n",
      "10/17 23:52:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:37:55  time: 1.1241  data_time: 0.0111  memory: 19902  grad_norm: 51.6235  loss: 13.0769  loss_cls: 0.6450  loss_bbox: 0.1500  loss_iou: 0.2309  d0.loss_cls: 0.6511  d0.loss_bbox: 0.1784  d0.loss_iou: 0.2624  d1.loss_cls: 0.6465  d1.loss_bbox: 0.1675  d1.loss_iou: 0.2469  d2.loss_cls: 0.6524  d2.loss_bbox: 0.1502  d2.loss_iou: 0.2302  d3.loss_cls: 0.6418  d3.loss_bbox: 0.1597  d3.loss_iou: 0.2328  d4.loss_cls: 0.6497  d4.loss_bbox: 0.1432  d4.loss_iou: 0.2253  enc_loss_cls: 0.6637  enc_loss_bbox: 0.2067  enc_loss_iou: 0.2946  dn_loss_cls: 0.3425  dn_loss_bbox: 0.2266  dn_loss_iou: 0.2779  d0.dn_loss_cls: 0.3842  d0.dn_loss_bbox: 0.4115  d0.dn_loss_iou: 0.4542  d1.dn_loss_cls: 0.3504  d1.dn_loss_bbox: 0.2796  d1.dn_loss_iou: 0.3379  d2.dn_loss_cls: 0.3418  d2.dn_loss_bbox: 0.2437  d2.dn_loss_iou: 0.2976  d3.dn_loss_cls: 0.3395  d3.dn_loss_bbox: 0.2307  d3.dn_loss_iou: 0.2845  d4.dn_loss_cls: 0.3400  d4.dn_loss_bbox: 0.2266  d4.dn_loss_iou: 0.2786\n",
      "10/17 23:53:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][150/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:35:37  time: 1.0969  data_time: 0.0105  memory: 19311  grad_norm: 42.8207  loss: 12.5334  loss_cls: 0.5813  loss_bbox: 0.1568  loss_iou: 0.2483  d0.loss_cls: 0.5910  d0.loss_bbox: 0.1794  d0.loss_iou: 0.2806  d1.loss_cls: 0.5874  d1.loss_bbox: 0.1630  d1.loss_iou: 0.2622  d2.loss_cls: 0.5919  d2.loss_bbox: 0.1534  d2.loss_iou: 0.2482  d3.loss_cls: 0.5849  d3.loss_bbox: 0.1573  d3.loss_iou: 0.2486  d4.loss_cls: 0.5805  d4.loss_bbox: 0.1570  d4.loss_iou: 0.2477  enc_loss_cls: 0.6069  enc_loss_bbox: 0.1952  enc_loss_iou: 0.3053  dn_loss_cls: 0.2281  dn_loss_bbox: 0.2575  dn_loss_iou: 0.3119  d0.dn_loss_cls: 0.2943  d0.dn_loss_bbox: 0.4344  d0.dn_loss_iou: 0.4959  d1.dn_loss_cls: 0.2419  d1.dn_loss_bbox: 0.3130  d1.dn_loss_iou: 0.3756  d2.dn_loss_cls: 0.2332  d2.dn_loss_bbox: 0.2780  d2.dn_loss_iou: 0.3333  d3.dn_loss_cls: 0.2285  d3.dn_loss_bbox: 0.2633  d3.dn_loss_iou: 0.3206  d4.dn_loss_cls: 0.2267  d4.dn_loss_bbox: 0.2575  d4.dn_loss_iou: 0.3128\n",
      "10/17 23:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][200/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:34:22  time: 1.1040  data_time: 0.0102  memory: 22247  grad_norm: 44.0661  loss: 11.3155  loss_cls: 0.5618  loss_bbox: 0.1432  loss_iou: 0.2219  d0.loss_cls: 0.5743  d0.loss_bbox: 0.1803  d0.loss_iou: 0.2577  d1.loss_cls: 0.5727  d1.loss_bbox: 0.1581  d1.loss_iou: 0.2381  d2.loss_cls: 0.5709  d2.loss_bbox: 0.1489  d2.loss_iou: 0.2245  d3.loss_cls: 0.5644  d3.loss_bbox: 0.1440  d3.loss_iou: 0.2223  d4.loss_cls: 0.5634  d4.loss_bbox: 0.1407  d4.loss_iou: 0.2215  enc_loss_cls: 0.5839  enc_loss_bbox: 0.1871  enc_loss_iou: 0.2734  dn_loss_cls: 0.1832  dn_loss_bbox: 0.2160  dn_loss_iou: 0.2650  d0.dn_loss_cls: 0.2612  d0.dn_loss_bbox: 0.3847  d0.dn_loss_iou: 0.4262  d1.dn_loss_cls: 0.2015  d1.dn_loss_bbox: 0.2687  d1.dn_loss_iou: 0.3216  d2.dn_loss_cls: 0.1834  d2.dn_loss_bbox: 0.2332  d2.dn_loss_iou: 0.2842  d3.dn_loss_cls: 0.1798  d3.dn_loss_bbox: 0.2197  d3.dn_loss_iou: 0.2713  d4.dn_loss_cls: 0.1814  d4.dn_loss_bbox: 0.2160  d4.dn_loss_iou: 0.2655\n",
      "10/17 23:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][250/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:32:45  time: 1.0915  data_time: 0.0103  memory: 20047  grad_norm: 42.6333  loss: 10.5591  loss_cls: 0.5164  loss_bbox: 0.1306  loss_iou: 0.2138  d0.loss_cls: 0.5284  d0.loss_bbox: 0.1514  d0.loss_iou: 0.2423  d1.loss_cls: 0.5202  d1.loss_bbox: 0.1422  d1.loss_iou: 0.2320  d2.loss_cls: 0.5199  d2.loss_bbox: 0.1349  d2.loss_iou: 0.2201  d3.loss_cls: 0.5169  d3.loss_bbox: 0.1317  d3.loss_iou: 0.2174  d4.loss_cls: 0.5144  d4.loss_bbox: 0.1307  d4.loss_iou: 0.2150  enc_loss_cls: 0.5392  enc_loss_bbox: 0.1765  enc_loss_iou: 0.2753  dn_loss_cls: 0.1516  dn_loss_bbox: 0.2141  dn_loss_iou: 0.2623  d0.dn_loss_cls: 0.2305  d0.dn_loss_bbox: 0.3569  d0.dn_loss_iou: 0.4148  d1.dn_loss_cls: 0.1719  d1.dn_loss_bbox: 0.2565  d1.dn_loss_iou: 0.3123  d2.dn_loss_cls: 0.1567  d2.dn_loss_bbox: 0.2249  d2.dn_loss_iou: 0.2771  d3.dn_loss_cls: 0.1500  d3.dn_loss_bbox: 0.2156  d3.dn_loss_iou: 0.2670  d4.dn_loss_cls: 0.1510  d4.dn_loss_bbox: 0.2140  d4.dn_loss_iou: 0.2626\n",
      "10/17 23:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][300/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:31:57  time: 1.1092  data_time: 0.0106  memory: 22482  grad_norm: 46.2011  loss: 11.2141  loss_cls: 0.5698  loss_bbox: 0.1350  loss_iou: 0.2280  d0.loss_cls: 0.5649  d0.loss_bbox: 0.1676  d0.loss_iou: 0.2634  d1.loss_cls: 0.5630  d1.loss_bbox: 0.1489  d1.loss_iou: 0.2415  d2.loss_cls: 0.5596  d2.loss_bbox: 0.1467  d2.loss_iou: 0.2389  d3.loss_cls: 0.5599  d3.loss_bbox: 0.1391  d3.loss_iou: 0.2320  d4.loss_cls: 0.5681  d4.loss_bbox: 0.1356  d4.loss_iou: 0.2294  enc_loss_cls: 0.5694  enc_loss_bbox: 0.1846  enc_loss_iou: 0.2882  dn_loss_cls: 0.1487  dn_loss_bbox: 0.2146  dn_loss_iou: 0.2810  d0.dn_loss_cls: 0.2396  d0.dn_loss_bbox: 0.3874  d0.dn_loss_iou: 0.4439  d1.dn_loss_cls: 0.1731  d1.dn_loss_bbox: 0.2645  d1.dn_loss_iou: 0.3368  d2.dn_loss_cls: 0.1552  d2.dn_loss_bbox: 0.2344  d2.dn_loss_iou: 0.3020  d3.dn_loss_cls: 0.1482  d3.dn_loss_bbox: 0.2190  d3.dn_loss_iou: 0.2870  d4.dn_loss_cls: 0.1484  d4.dn_loss_bbox: 0.2149  d4.dn_loss_iou: 0.2816\n",
      "10/17 23:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][350/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:31:02  time: 1.1063  data_time: 0.0101  memory: 20509  grad_norm: 41.9401  loss: 10.9827  loss_cls: 0.5313  loss_bbox: 0.1469  loss_iou: 0.2207  d0.loss_cls: 0.5523  d0.loss_bbox: 0.1693  d0.loss_iou: 0.2426  d1.loss_cls: 0.5489  d1.loss_bbox: 0.1504  d1.loss_iou: 0.2261  d2.loss_cls: 0.5401  d2.loss_bbox: 0.1489  d2.loss_iou: 0.2250  d3.loss_cls: 0.5303  d3.loss_bbox: 0.1489  d3.loss_iou: 0.2239  d4.loss_cls: 0.5324  d4.loss_bbox: 0.1443  d4.loss_iou: 0.2206  enc_loss_cls: 0.5579  enc_loss_bbox: 0.2024  enc_loss_iou: 0.2815  dn_loss_cls: 0.1335  dn_loss_bbox: 0.2294  dn_loss_iou: 0.2641  d0.dn_loss_cls: 0.2234  d0.dn_loss_bbox: 0.4223  d0.dn_loss_iou: 0.4407  d1.dn_loss_cls: 0.1605  d1.dn_loss_bbox: 0.2874  d1.dn_loss_iou: 0.3235  d2.dn_loss_cls: 0.1410  d2.dn_loss_bbox: 0.2540  d2.dn_loss_iou: 0.2887  d3.dn_loss_cls: 0.1337  d3.dn_loss_bbox: 0.2356  d3.dn_loss_iou: 0.2723  d4.dn_loss_cls: 0.1335  d4.dn_loss_bbox: 0.2296  d4.dn_loss_iou: 0.2648\n",
      "10/17 23:57:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][400/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:29:52  time: 1.0961  data_time: 0.0101  memory: 19078  grad_norm: 45.9057  loss: 10.9453  loss_cls: 0.5560  loss_bbox: 0.1513  loss_iou: 0.2198  d0.loss_cls: 0.5706  d0.loss_bbox: 0.1767  d0.loss_iou: 0.2512  d1.loss_cls: 0.5639  d1.loss_bbox: 0.1608  d1.loss_iou: 0.2322  d2.loss_cls: 0.5732  d2.loss_bbox: 0.1458  d2.loss_iou: 0.2164  d3.loss_cls: 0.5577  d3.loss_bbox: 0.1579  d3.loss_iou: 0.2245  d4.loss_cls: 0.5475  d4.loss_bbox: 0.1608  d4.loss_iou: 0.2270  enc_loss_cls: 0.5914  enc_loss_bbox: 0.1945  enc_loss_iou: 0.2789  dn_loss_cls: 0.1247  dn_loss_bbox: 0.2103  dn_loss_iou: 0.2548  d0.dn_loss_cls: 0.2219  d0.dn_loss_bbox: 0.3993  d0.dn_loss_iou: 0.4301  d1.dn_loss_cls: 0.1531  d1.dn_loss_bbox: 0.2608  d1.dn_loss_iou: 0.3123  d2.dn_loss_cls: 0.1324  d2.dn_loss_bbox: 0.2253  d2.dn_loss_iou: 0.2722  d3.dn_loss_cls: 0.1236  d3.dn_loss_bbox: 0.2148  d3.dn_loss_iou: 0.2614  d4.dn_loss_cls: 0.1239  d4.dn_loss_bbox: 0.2108  d4.dn_loss_iou: 0.2554\n",
      "10/17 23:58:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][450/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:28:56  time: 1.1046  data_time: 0.0102  memory: 18877  grad_norm: 42.2834  loss: 10.9759  loss_cls: 0.5120  loss_bbox: 0.1522  loss_iou: 0.2326  d0.loss_cls: 0.5324  d0.loss_bbox: 0.1727  d0.loss_iou: 0.2625  d1.loss_cls: 0.5257  d1.loss_bbox: 0.1608  d1.loss_iou: 0.2444  d2.loss_cls: 0.5187  d2.loss_bbox: 0.1589  d2.loss_iou: 0.2402  d3.loss_cls: 0.5103  d3.loss_bbox: 0.1542  d3.loss_iou: 0.2351  d4.loss_cls: 0.5111  d4.loss_bbox: 0.1557  d4.loss_iou: 0.2338  enc_loss_cls: 0.5477  enc_loss_bbox: 0.1988  enc_loss_iou: 0.2895  dn_loss_cls: 0.1272  dn_loss_bbox: 0.2250  dn_loss_iou: 0.2690  d0.dn_loss_cls: 0.2268  d0.dn_loss_bbox: 0.4178  d0.dn_loss_iou: 0.4498  d1.dn_loss_cls: 0.1572  d1.dn_loss_bbox: 0.2862  d1.dn_loss_iou: 0.3349  d2.dn_loss_cls: 0.1364  d2.dn_loss_bbox: 0.2471  d2.dn_loss_iou: 0.2933  d3.dn_loss_cls: 0.1282  d3.dn_loss_bbox: 0.2292  d3.dn_loss_iou: 0.2762  d4.dn_loss_cls: 0.1277  d4.dn_loss_bbox: 0.2252  d4.dn_loss_iou: 0.2695\n",
      "10/17 23:59:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][500/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:28:06  time: 1.1092  data_time: 0.0101  memory: 19824  grad_norm: 43.2608  loss: 9.8821  loss_cls: 0.4544  loss_bbox: 0.1408  loss_iou: 0.1997  d0.loss_cls: 0.4765  d0.loss_bbox: 0.1610  d0.loss_iou: 0.2283  d1.loss_cls: 0.4687  d1.loss_bbox: 0.1526  d1.loss_iou: 0.2153  d2.loss_cls: 0.4574  d2.loss_bbox: 0.1464  d2.loss_iou: 0.2055  d3.loss_cls: 0.4528  d3.loss_bbox: 0.1450  d3.loss_iou: 0.2024  d4.loss_cls: 0.4537  d4.loss_bbox: 0.1418  d4.loss_iou: 0.2006  enc_loss_cls: 0.4888  enc_loss_bbox: 0.1831  enc_loss_iou: 0.2546  dn_loss_cls: 0.1178  dn_loss_bbox: 0.2175  dn_loss_iou: 0.2403  d0.dn_loss_cls: 0.1935  d0.dn_loss_bbox: 0.4016  d0.dn_loss_iou: 0.4062  d1.dn_loss_cls: 0.1350  d1.dn_loss_bbox: 0.2682  d1.dn_loss_iou: 0.2954  d2.dn_loss_cls: 0.1224  d2.dn_loss_bbox: 0.2341  d2.dn_loss_iou: 0.2604  d3.dn_loss_cls: 0.1169  d3.dn_loss_bbox: 0.2211  d3.dn_loss_iou: 0.2463  d4.dn_loss_cls: 0.1175  d4.dn_loss_bbox: 0.2177  d4.dn_loss_iou: 0.2410\n",
      "10/18 00:00:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][550/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:27:00  time: 1.0951  data_time: 0.0102  memory: 19512  grad_norm: 41.3351  loss: 10.5539  loss_cls: 0.5243  loss_bbox: 0.1302  loss_iou: 0.2143  d0.loss_cls: 0.5382  d0.loss_bbox: 0.1611  d0.loss_iou: 0.2458  d1.loss_cls: 0.5291  d1.loss_bbox: 0.1416  d1.loss_iou: 0.2312  d2.loss_cls: 0.5271  d2.loss_bbox: 0.1348  d2.loss_iou: 0.2219  d3.loss_cls: 0.5260  d3.loss_bbox: 0.1331  d3.loss_iou: 0.2188  d4.loss_cls: 0.5243  d4.loss_bbox: 0.1330  d4.loss_iou: 0.2169  enc_loss_cls: 0.5507  enc_loss_bbox: 0.1777  enc_loss_iou: 0.2762  dn_loss_cls: 0.1276  dn_loss_bbox: 0.2121  dn_loss_iou: 0.2601  d0.dn_loss_cls: 0.2131  d0.dn_loss_bbox: 0.3863  d0.dn_loss_iou: 0.4221  d1.dn_loss_cls: 0.1470  d1.dn_loss_bbox: 0.2619  d1.dn_loss_iou: 0.3168  d2.dn_loss_cls: 0.1330  d2.dn_loss_bbox: 0.2293  d2.dn_loss_iou: 0.2798  d3.dn_loss_cls: 0.1258  d3.dn_loss_bbox: 0.2158  d3.dn_loss_iou: 0.2661  d4.dn_loss_cls: 0.1276  d4.dn_loss_bbox: 0.2122  d4.dn_loss_iou: 0.2610\n",
      "10/18 00:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][600/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:26:05  time: 1.1052  data_time: 0.0103  memory: 27448  grad_norm: 42.4552  loss: 10.5662  loss_cls: 0.4861  loss_bbox: 0.1398  loss_iou: 0.2277  d0.loss_cls: 0.4949  d0.loss_bbox: 0.1659  d0.loss_iou: 0.2565  d1.loss_cls: 0.4879  d1.loss_bbox: 0.1552  d1.loss_iou: 0.2457  d2.loss_cls: 0.4832  d2.loss_bbox: 0.1519  d2.loss_iou: 0.2409  d3.loss_cls: 0.4830  d3.loss_bbox: 0.1458  d3.loss_iou: 0.2341  d4.loss_cls: 0.4834  d4.loss_bbox: 0.1447  d4.loss_iou: 0.2319  enc_loss_cls: 0.5037  enc_loss_bbox: 0.1888  enc_loss_iou: 0.2867  dn_loss_cls: 0.1158  dn_loss_bbox: 0.2264  dn_loss_iou: 0.2809  d0.dn_loss_cls: 0.2035  d0.dn_loss_bbox: 0.3890  d0.dn_loss_iou: 0.4390  d1.dn_loss_cls: 0.1405  d1.dn_loss_bbox: 0.2726  d1.dn_loss_iou: 0.3377  d2.dn_loss_cls: 0.1248  d2.dn_loss_bbox: 0.2412  d2.dn_loss_iou: 0.3015  d3.dn_loss_cls: 0.1166  d3.dn_loss_bbox: 0.2281  d3.dn_loss_iou: 0.2873  d4.dn_loss_cls: 0.1152  d4.dn_loss_bbox: 0.2266  d4.dn_loss_iou: 0.2817\n",
      "10/18 00:02:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][650/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:24:35  time: 1.0639  data_time: 0.0102  memory: 18282  grad_norm: 40.0027  loss: 10.3058  loss_cls: 0.4551  loss_bbox: 0.1536  loss_iou: 0.2283  d0.loss_cls: 0.4682  d0.loss_bbox: 0.1841  d0.loss_iou: 0.2591  d1.loss_cls: 0.4552  d1.loss_bbox: 0.1722  d1.loss_iou: 0.2442  d2.loss_cls: 0.4602  d2.loss_bbox: 0.1564  d2.loss_iou: 0.2312  d3.loss_cls: 0.4608  d3.loss_bbox: 0.1518  d3.loss_iou: 0.2238  d4.loss_cls: 0.4557  d4.loss_bbox: 0.1524  d4.loss_iou: 0.2252  enc_loss_cls: 0.4764  enc_loss_bbox: 0.2093  enc_loss_iou: 0.2918  dn_loss_cls: 0.1062  dn_loss_bbox: 0.2282  dn_loss_iou: 0.2679  d0.dn_loss_cls: 0.1863  d0.dn_loss_bbox: 0.3896  d0.dn_loss_iou: 0.4345  d1.dn_loss_cls: 0.1239  d1.dn_loss_bbox: 0.2768  d1.dn_loss_iou: 0.3258  d2.dn_loss_cls: 0.1102  d2.dn_loss_bbox: 0.2423  d2.dn_loss_iou: 0.2866  d3.dn_loss_cls: 0.1063  d3.dn_loss_bbox: 0.2305  d3.dn_loss_iou: 0.2741  d4.dn_loss_cls: 0.1056  d4.dn_loss_bbox: 0.2277  d4.dn_loss_iou: 0.2683\n",
      "10/18 00:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][700/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:24:04  time: 1.1317  data_time: 0.0102  memory: 20424  grad_norm: 42.2956  loss: 9.8364  loss_cls: 0.4546  loss_bbox: 0.1399  loss_iou: 0.2236  d0.loss_cls: 0.4670  d0.loss_bbox: 0.1655  d0.loss_iou: 0.2492  d1.loss_cls: 0.4626  d1.loss_bbox: 0.1534  d1.loss_iou: 0.2334  d2.loss_cls: 0.4534  d2.loss_bbox: 0.1469  d2.loss_iou: 0.2288  d3.loss_cls: 0.4513  d3.loss_bbox: 0.1465  d3.loss_iou: 0.2287  d4.loss_cls: 0.4546  d4.loss_bbox: 0.1402  d4.loss_iou: 0.2223  enc_loss_cls: 0.4694  enc_loss_bbox: 0.2050  enc_loss_iou: 0.2889  dn_loss_cls: 0.1007  dn_loss_bbox: 0.1971  dn_loss_iou: 0.2462  d0.dn_loss_cls: 0.1892  d0.dn_loss_bbox: 0.3635  d0.dn_loss_iou: 0.4031  d1.dn_loss_cls: 0.1246  d1.dn_loss_bbox: 0.2464  d1.dn_loss_iou: 0.3004  d2.dn_loss_cls: 0.1081  d2.dn_loss_bbox: 0.2108  d2.dn_loss_iou: 0.2633  d3.dn_loss_cls: 0.1012  d3.dn_loss_bbox: 0.1998  d3.dn_loss_iou: 0.2517  d4.dn_loss_cls: 0.1015  d4.dn_loss_bbox: 0.1972  d4.dn_loss_iou: 0.2465\n",
      "10/18 00:04:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][750/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:23:11  time: 1.1053  data_time: 0.0103  memory: 20538  grad_norm: 45.3499  loss: 9.8311  loss_cls: 0.4903  loss_bbox: 0.1290  loss_iou: 0.2084  d0.loss_cls: 0.5047  d0.loss_bbox: 0.1514  d0.loss_iou: 0.2322  d1.loss_cls: 0.5058  d1.loss_bbox: 0.1343  d1.loss_iou: 0.2112  d2.loss_cls: 0.5000  d2.loss_bbox: 0.1268  d2.loss_iou: 0.2055  d3.loss_cls: 0.4974  d3.loss_bbox: 0.1266  d3.loss_iou: 0.2091  d4.loss_cls: 0.4871  d4.loss_bbox: 0.1292  d4.loss_iou: 0.2105  enc_loss_cls: 0.4992  enc_loss_bbox: 0.1783  enc_loss_iou: 0.2634  dn_loss_cls: 0.1058  dn_loss_bbox: 0.1897  dn_loss_iou: 0.2386  d0.dn_loss_cls: 0.2000  d0.dn_loss_bbox: 0.3611  d0.dn_loss_iou: 0.4044  d1.dn_loss_cls: 0.1322  d1.dn_loss_bbox: 0.2390  d1.dn_loss_iou: 0.2943  d2.dn_loss_cls: 0.1166  d2.dn_loss_bbox: 0.2066  d2.dn_loss_iou: 0.2579  d3.dn_loss_cls: 0.1084  d3.dn_loss_bbox: 0.1948  d3.dn_loss_iou: 0.2457  d4.dn_loss_cls: 0.1065  d4.dn_loss_bbox: 0.1899  d4.dn_loss_iou: 0.2393\n",
      "10/18 00:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][800/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:22:07  time: 1.0920  data_time: 0.0102  memory: 19195  grad_norm: 45.0059  loss: 10.1836  loss_cls: 0.4808  loss_bbox: 0.1446  loss_iou: 0.2256  d0.loss_cls: 0.5059  d0.loss_bbox: 0.1620  d0.loss_iou: 0.2401  d1.loss_cls: 0.4961  d1.loss_bbox: 0.1483  d1.loss_iou: 0.2217  d2.loss_cls: 0.4951  d2.loss_bbox: 0.1445  d2.loss_iou: 0.2186  d3.loss_cls: 0.4939  d3.loss_bbox: 0.1388  d3.loss_iou: 0.2153  d4.loss_cls: 0.4901  d4.loss_bbox: 0.1389  d4.loss_iou: 0.2176  enc_loss_cls: 0.5072  enc_loss_bbox: 0.1990  enc_loss_iou: 0.2774  dn_loss_cls: 0.1025  dn_loss_bbox: 0.2098  dn_loss_iou: 0.2526  d0.dn_loss_cls: 0.1991  d0.dn_loss_bbox: 0.3777  d0.dn_loss_iou: 0.4194  d1.dn_loss_cls: 0.1287  d1.dn_loss_bbox: 0.2652  d1.dn_loss_iou: 0.3096  d2.dn_loss_cls: 0.1101  d2.dn_loss_bbox: 0.2277  d2.dn_loss_iou: 0.2744  d3.dn_loss_cls: 0.1043  d3.dn_loss_bbox: 0.2147  d3.dn_loss_iou: 0.2593  d4.dn_loss_cls: 0.1031  d4.dn_loss_bbox: 0.2102  d4.dn_loss_iou: 0.2534\n",
      "10/18 00:06:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][850/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:21:06  time: 1.0936  data_time: 0.0100  memory: 24968  grad_norm: 37.4561  loss: 10.2611  loss_cls: 0.4577  loss_bbox: 0.1506  loss_iou: 0.2316  d0.loss_cls: 0.4728  d0.loss_bbox: 0.1775  d0.loss_iou: 0.2619  d1.loss_cls: 0.4650  d1.loss_bbox: 0.1634  d1.loss_iou: 0.2456  d2.loss_cls: 0.4660  d2.loss_bbox: 0.1564  d2.loss_iou: 0.2346  d3.loss_cls: 0.4591  d3.loss_bbox: 0.1507  d3.loss_iou: 0.2323  d4.loss_cls: 0.4618  d4.loss_bbox: 0.1475  d4.loss_iou: 0.2303  enc_loss_cls: 0.4812  enc_loss_bbox: 0.1990  enc_loss_iou: 0.2918  dn_loss_cls: 0.1110  dn_loss_bbox: 0.2128  dn_loss_iou: 0.2613  d0.dn_loss_cls: 0.1973  d0.dn_loss_bbox: 0.3861  d0.dn_loss_iou: 0.4287  d1.dn_loss_cls: 0.1320  d1.dn_loss_bbox: 0.2637  d1.dn_loss_iou: 0.3188  d2.dn_loss_cls: 0.1168  d2.dn_loss_bbox: 0.2320  d2.dn_loss_iou: 0.2827  d3.dn_loss_cls: 0.1105  d3.dn_loss_bbox: 0.2171  d3.dn_loss_iou: 0.2678  d4.dn_loss_cls: 0.1108  d4.dn_loss_bbox: 0.2130  d4.dn_loss_iou: 0.2619\n",
      "10/18 00:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][900/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:20:14  time: 1.1067  data_time: 0.0105  memory: 20460  grad_norm: 41.2777  loss: 10.8997  loss_cls: 0.5053  loss_bbox: 0.1559  loss_iou: 0.2421  d0.loss_cls: 0.5282  d0.loss_bbox: 0.1763  d0.loss_iou: 0.2686  d1.loss_cls: 0.5101  d1.loss_bbox: 0.1708  d1.loss_iou: 0.2550  d2.loss_cls: 0.5138  d2.loss_bbox: 0.1644  d2.loss_iou: 0.2484  d3.loss_cls: 0.5104  d3.loss_bbox: 0.1594  d3.loss_iou: 0.2438  d4.loss_cls: 0.5067  d4.loss_bbox: 0.1574  d4.loss_iou: 0.2420  enc_loss_cls: 0.5207  enc_loss_bbox: 0.2189  enc_loss_iou: 0.3052  dn_loss_cls: 0.1107  dn_loss_bbox: 0.2288  dn_loss_iou: 0.2801  d0.dn_loss_cls: 0.2026  d0.dn_loss_bbox: 0.3834  d0.dn_loss_iou: 0.4408  d1.dn_loss_cls: 0.1344  d1.dn_loss_bbox: 0.2722  d1.dn_loss_iou: 0.3347  d2.dn_loss_cls: 0.1184  d2.dn_loss_bbox: 0.2421  d2.dn_loss_iou: 0.3002  d3.dn_loss_cls: 0.1114  d3.dn_loss_bbox: 0.2309  d3.dn_loss_iou: 0.2848  d4.dn_loss_cls: 0.1115  d4.dn_loss_bbox: 0.2288  d4.dn_loss_iou: 0.2806\n",
      "10/18 00:08:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][950/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:19:25  time: 1.1148  data_time: 0.0101  memory: 21577  grad_norm: 40.6465  loss: 9.8544  loss_cls: 0.4654  loss_bbox: 0.1344  loss_iou: 0.2204  d0.loss_cls: 0.4827  d0.loss_bbox: 0.1550  d0.loss_iou: 0.2416  d1.loss_cls: 0.4758  d1.loss_bbox: 0.1428  d1.loss_iou: 0.2311  d2.loss_cls: 0.4740  d2.loss_bbox: 0.1348  d2.loss_iou: 0.2250  d3.loss_cls: 0.4623  d3.loss_bbox: 0.1371  d3.loss_iou: 0.2225  d4.loss_cls: 0.4654  d4.loss_bbox: 0.1342  d4.loss_iou: 0.2197  enc_loss_cls: 0.4838  enc_loss_bbox: 0.1798  enc_loss_iou: 0.2759  dn_loss_cls: 0.1085  dn_loss_bbox: 0.1926  dn_loss_iou: 0.2545  d0.dn_loss_cls: 0.1926  d0.dn_loss_bbox: 0.3530  d0.dn_loss_iou: 0.4042  d1.dn_loss_cls: 0.1289  d1.dn_loss_bbox: 0.2355  d1.dn_loss_iou: 0.3036  d2.dn_loss_cls: 0.1139  d2.dn_loss_bbox: 0.2086  d2.dn_loss_iou: 0.2719  d3.dn_loss_cls: 0.1087  d3.dn_loss_bbox: 0.1966  d3.dn_loss_iou: 0.2607  d4.dn_loss_cls: 0.1086  d4.dn_loss_bbox: 0.1929  d4.dn_loss_iou: 0.2554\n",
      "10/18 00:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: grounding_dino_swin-b_finetune_16xb2_1x_coco_20241017_235014\n",
      "10/18 00:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/layers/positional_encoding.py:103: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/layers/transformer/utils.py:71: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = temperature**(2 * (dim_t // 2) / num_feats)\n",
      "/opt/conda/lib/python3.10/site-packages/mmcv/cnn/bricks/transformer.py:524: UserWarning: position encoding of key ismissing in MultiheadAttention.\n",
      "  warnings.warn(f'position encoding of key is'\n",
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/dense_heads/grounding_dino_head.py:427: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bbox_index = indexes // num_classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/18 00:09:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 50/239]    eta: 0:01:39  time: 0.5273  data_time: 0.0117  memory: 20209  \n",
      "10/18 00:09:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][100/239]    eta: 0:01:13  time: 0.5231  data_time: 0.0076  memory: 3204  \n",
      "10/18 00:10:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][150/239]    eta: 0:00:46  time: 0.5218  data_time: 0.0067  memory: 3204  \n",
      "10/18 00:10:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][200/239]    eta: 0:00:20  time: 0.5202  data_time: 0.0064  memory: 3204  \n",
      "10/18 00:10:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=1.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=14.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=7.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.607\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.544\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.608\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.813\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.817\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.817\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.565\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.873\n",
      "10/18 00:11:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.524 0.607 0.544 0.021 0.128 0.608\n",
      "10/18 00:11:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][239/239]    coco/bbox_mAP: 0.5240  coco/bbox_mAP_50: 0.6070  coco/bbox_mAP_75: 0.5440  coco/bbox_mAP_s: 0.0210  coco/bbox_mAP_m: 0.1280  coco/bbox_mAP_l: 0.6080  data_time: 0.0078  time: 0.5213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmengine/hooks/early_stopping_hook.py:148: UserWarning: Skip early stopping process since the evaluation results (dict_keys(['coco/bbox_mAP', 'coco/bbox_mAP_50', 'coco/bbox_mAP_75', 'coco/bbox_mAP_s', 'coco/bbox_mAP_m', 'coco/bbox_mAP_l'])) do not include `monitor` (bbox_mAP).\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/18 00:11:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: grounding_dino_swin-b_finetune_16xb2_1x_coco_20241017_235014\n",
      "10/18 00:12:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 50/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:17:46  time: 1.0771  data_time: 0.0158  memory: 21480  grad_norm: 40.3115  loss: 9.6978  loss_cls: 0.4492  loss_bbox: 0.1346  loss_iou: 0.2251  d0.loss_cls: 0.4663  d0.loss_bbox: 0.1537  d0.loss_iou: 0.2458  d1.loss_cls: 0.4582  d1.loss_bbox: 0.1388  d1.loss_iou: 0.2307  d2.loss_cls: 0.4551  d2.loss_bbox: 0.1344  d2.loss_iou: 0.2266  d3.loss_cls: 0.4490  d3.loss_bbox: 0.1363  d3.loss_iou: 0.2270  d4.loss_cls: 0.4489  d4.loss_bbox: 0.1354  d4.loss_iou: 0.2256  enc_loss_cls: 0.4729  enc_loss_bbox: 0.1695  enc_loss_iou: 0.2731  dn_loss_cls: 0.0854  dn_loss_bbox: 0.1941  dn_loss_iou: 0.2637  d0.dn_loss_cls: 0.1750  d0.dn_loss_bbox: 0.3484  d0.dn_loss_iou: 0.4224  d1.dn_loss_cls: 0.1105  d1.dn_loss_bbox: 0.2389  d1.dn_loss_iou: 0.3174  d2.dn_loss_cls: 0.0933  d2.dn_loss_bbox: 0.2081  d2.dn_loss_iou: 0.2818  d3.dn_loss_cls: 0.0879  d3.dn_loss_bbox: 0.1985  d3.dn_loss_iou: 0.2704  d4.dn_loss_cls: 0.0866  d4.dn_loss_bbox: 0.1943  d4.dn_loss_iou: 0.2645\n",
      "10/18 00:13:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:17:01  time: 1.1243  data_time: 0.0104  memory: 19950  grad_norm: 42.1238  loss: 9.8343  loss_cls: 0.4444  loss_bbox: 0.1435  loss_iou: 0.2088  d0.loss_cls: 0.4696  d0.loss_bbox: 0.1591  d0.loss_iou: 0.2327  d1.loss_cls: 0.4647  d1.loss_bbox: 0.1475  d1.loss_iou: 0.2173  d2.loss_cls: 0.4618  d2.loss_bbox: 0.1417  d2.loss_iou: 0.2093  d3.loss_cls: 0.4514  d3.loss_bbox: 0.1422  d3.loss_iou: 0.2108  d4.loss_cls: 0.4444  d4.loss_bbox: 0.1444  d4.loss_iou: 0.2097  enc_loss_cls: 0.4781  enc_loss_bbox: 0.1845  enc_loss_iou: 0.2637  dn_loss_cls: 0.0935  dn_loss_bbox: 0.2205  dn_loss_iou: 0.2488  d0.dn_loss_cls: 0.1865  d0.dn_loss_bbox: 0.3919  d0.dn_loss_iou: 0.4166  d1.dn_loss_cls: 0.1185  d1.dn_loss_bbox: 0.2710  d1.dn_loss_iou: 0.3057  d2.dn_loss_cls: 0.1012  d2.dn_loss_bbox: 0.2407  d2.dn_loss_iou: 0.2707  d3.dn_loss_cls: 0.0944  d3.dn_loss_bbox: 0.2254  d3.dn_loss_iou: 0.2549  d4.dn_loss_cls: 0.0945  d4.dn_loss_bbox: 0.2205  d4.dn_loss_iou: 0.2493\n",
      "10/18 00:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][150/983]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 3:16:03  time: 1.0974  data_time: 0.0107  memory: 19340  grad_norm: 45.9260  loss: 9.8351  loss_cls: 0.4439  loss_bbox: 0.1344  loss_iou: 0.2262  d0.loss_cls: 0.4578  d0.loss_bbox: 0.1551  d0.loss_iou: 0.2500  d1.loss_cls: 0.4484  d1.loss_bbox: 0.1489  d1.loss_iou: 0.2384  d2.loss_cls: 0.4502  d2.loss_bbox: 0.1358  d2.loss_iou: 0.2259  d3.loss_cls: 0.4428  d3.loss_bbox: 0.1334  d3.loss_iou: 0.2253  d4.loss_cls: 0.4426  d4.loss_bbox: 0.1358  d4.loss_iou: 0.2262  enc_loss_cls: 0.4775  enc_loss_bbox: 0.1799  enc_loss_iou: 0.2778  dn_loss_cls: 0.0959  dn_loss_bbox: 0.2087  dn_loss_iou: 0.2629  d0.dn_loss_cls: 0.1759  d0.dn_loss_bbox: 0.3920  d0.dn_loss_iou: 0.4131  d1.dn_loss_cls: 0.1120  d1.dn_loss_bbox: 0.2573  d1.dn_loss_iou: 0.3116  d2.dn_loss_cls: 0.0987  d2.dn_loss_bbox: 0.2251  d2.dn_loss_iou: 0.2798  d3.dn_loss_cls: 0.0959  d3.dn_loss_bbox: 0.2137  d3.dn_loss_iou: 0.2678  d4.dn_loss_cls: 0.0960  d4.dn_loss_bbox: 0.2089  d4.dn_loss_iou: 0.2634\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation annotation file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_ann_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 학습 시작\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:1777\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_compile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:96\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mval_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_begin\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:112\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:128\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_idx\u001b[38;5;241m=\u001b[39midx, data_batch\u001b[38;5;241m=\u001b[39mdata_batch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Enable gradient accumulation mode and avoid unnecessary gradient\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# synchronization during gradient accumulation process.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# outputs should be a dict of loss.\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    133\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[1;32m    134\u001b[0m     data_batch\u001b[38;5;241m=\u001b[39mdata_batch,\n\u001b[1;32m    135\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/model/base_model/base_model.py:114\u001b[0m, in \u001b[0;36mBaseModel.train_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optim_wrapper\u001b[38;5;241m.\u001b[39moptim_context(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    113\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preprocessor(data, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 114\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    115\u001b[0m parsed_losses, log_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_losses(losses)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    116\u001b[0m optim_wrapper\u001b[38;5;241m.\u001b[39mupdate_params(parsed_losses)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/model/base_model/base_model.py:346\u001b[0m, in \u001b[0;36mBaseModel._run_forward\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Unpacks data for :meth:`forward`\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    dict or list: Results of training or testing mode.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 346\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    348\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mdata, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/base.py:92\u001b[0m, in \u001b[0;36mBaseDetector.forward\u001b[0;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The unified entry for a forward process in both training and test.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mThe method should accept three modes: \"tensor\", \"predict\" and \"loss\":\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    - If ``mode=\"loss\"``, return a dict of tensor.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(inputs, data_samples)\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/grounding_dino.py:497\u001b[0m, in \u001b[0;36mGroundingDINO.loss\u001b[0;34m(self, batch_inputs, batch_data_samples)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     visual_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_feat(batch_inputs)\n\u001b[0;32m--> 497\u001b[0m head_inputs_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisual_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbatch_data_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39mloss(\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhead_inputs_dict, batch_data_samples\u001b[38;5;241m=\u001b[39mbatch_data_samples)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/grounding_dino.py:319\u001b[0m, in \u001b[0;36mGroundingDINO.forward_transformer\u001b[0;34m(self, img_feats, text_dict, batch_data_samples)\u001b[0m\n\u001b[1;32m    315\u001b[0m tmp_dec_in, head_inputs_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_decoder(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_outputs_dict, batch_data_samples\u001b[38;5;241m=\u001b[39mbatch_data_samples)\n\u001b[1;32m    317\u001b[0m decoder_inputs_dict\u001b[38;5;241m.\u001b[39mupdate(tmp_dec_in)\n\u001b[0;32m--> 319\u001b[0m decoder_outputs_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoder_inputs_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m head_inputs_dict\u001b[38;5;241m.\u001b[39mupdate(decoder_outputs_dict)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m head_inputs_dict\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/detectors/dino.py:265\u001b[0m, in \u001b[0;36mDINO.forward_decoder\u001b[0;34m(self, query, memory, memory_mask, reference_points, spatial_shapes, level_start_index, valid_ratios, dn_mask, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_decoder\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    217\u001b[0m                     query: Tensor,\n\u001b[1;32m    218\u001b[0m                     memory: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m                     dn_mask: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    225\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward with Transformer decoder.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    The forward procedure of the transformer is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m        the initial and intermediate reference_points.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     inter_states, references \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mself_attn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspatial_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspatial_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel_start_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel_start_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreg_branches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbbox_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_branches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_queries:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# NOTE: This is to make sure label_embeding can be involved to\u001b[39;00m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;66;03m# produce loss even if there is no denoising query (no ground truth\u001b[39;00m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;66;03m# target in this GPU), otherwise, this will raise runtime error in\u001b[39;00m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# distributed training.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m         inter_states[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdn_query_generator\u001b[38;5;241m.\u001b[39mlabel_embedding\u001b[38;5;241m.\u001b[39mweight[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/layers/transformer/dino_layers.py:87\u001b[0m, in \u001b[0;36mDinoTransformerDecoder.forward\u001b[0;34m(self, query, value, key_padding_mask, self_attn_mask, reference_points, spatial_shapes, level_start_index, valid_ratios, reg_branches, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m query_sine_embed \u001b[38;5;241m=\u001b[39m coordinate_to_encoding(\n\u001b[1;32m     84\u001b[0m     reference_points_input[:, :, \u001b[38;5;241m0\u001b[39m, :])\n\u001b[1;32m     85\u001b[0m query_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_point_head(query_sine_embed)\n\u001b[0;32m---> 87\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mself_attn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspatial_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspatial_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel_start_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel_start_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_points_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reg_branches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m reg_branches[lid](query)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/models/layers/transformer/grounding_dino_layers.py:119\u001b[0m, in \u001b[0;36mGroundingDinoTransformerDecoderLayer.forward\u001b[0;34m(self, query, key, value, query_pos, key_pos, self_attn_mask, cross_attn_mask, key_padding_mask, memory_text, text_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms[\u001b[38;5;241m1\u001b[39m](query)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# cross attention between query and image\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms[\u001b[38;5;241m2\u001b[39m](query)\n\u001b[1;32m    129\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(query)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/utils/misc.py:395\u001b[0m, in \u001b[0;36mdeprecated_api_warning.<locals>.api_warning_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m             kwargs[dst_arg_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(src_arg_name)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# apply converted arguments to the decorated method\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mold_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmcv/ops/multi_scale_deform_attn.py:335\u001b[0m, in \u001b[0;36mMultiScaleDeformableAttention.forward\u001b[0;34m(self, query, key, value, identity, query_pos, key_padding_mask, reference_points, spatial_shapes, level_start_index, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m bs, num_query, _ \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    334\u001b[0m bs, num_value, _ \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (spatial_shapes[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m spatial_shapes[:, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m num_value\n\u001b[1;32m    337\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_proj(value)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습 시작 전에 검증 어노테이션 파일 존재 여부 확인\n",
    "if not os.path.exists(val_ann_file):\n",
    "    raise FileNotFoundError(f'Validation annotation file not found: {val_ann_file}')\n",
    "\n",
    "# 학습 시작\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

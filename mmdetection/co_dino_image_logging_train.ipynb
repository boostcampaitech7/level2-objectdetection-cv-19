{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import types\n",
    "import warnings\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.hooks import EarlyStoppingHook, Hook\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "from mmdet.registry import MODELS\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "import wandb\n",
    "from pycocotools.coco import COCO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InitHook(Hook):\n",
    "    def before_run(self, runner):\n",
    "        \"\"\"\n",
    "        모델의 평가 설정을 초기화하는 Hook.\n",
    "        cfg를 SimpleNamespace로 변환하지 않고 mmengine의 Config 객체를 유지합니다.\n",
    "        \"\"\"\n",
    "        # eval_module에 따라 test_cfg 설정\n",
    "        eval_module = runner.cfg.model.eval_module\n",
    "        if eval_module == 'detr':\n",
    "            # 필요에 따라 추가 설정 가능\n",
    "            pass\n",
    "        elif eval_module == 'one-stage':\n",
    "            pass\n",
    "        elif eval_module == 'two-stage':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown eval_module: {eval_module}\")\n",
    "        \n",
    "        # 필수 필드가 누락되지 않도록 확인 및 추가\n",
    "        if not hasattr(runner.cfg.model.test_cfg, 'score_thr'):\n",
    "            runner.cfg.model.test_cfg.score_thr = 0.05  # 기본값 설정\n",
    "            print(\"InitHook: Added 'score_thr' to test_cfg with default value 0.05.\")\n",
    "        \n",
    "        print(\"InitHook: runner.cfg.model.test_cfg has been set.\")\n",
    "        print(f\"runner.cfg.model.test_cfg: {runner.cfg.model.test_cfg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopMisclassifiedImagesHook(Hook):\n",
    "    def __init__(self, dataset, ann_file, work_dir, top_k=20, score_thr=0.3):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.ann_file = ann_file\n",
    "        self.work_dir = work_dir\n",
    "        self.top_k = top_k\n",
    "        self.score_thr = score_thr\n",
    "\n",
    "    def after_val_epoch(self, runner, **kwargs):\n",
    "        print(\"TopMisclassifiedImagesHook: after_val_epoch called\")\n",
    "        print(f\"runner.cfg.model.test_cfg: {runner.cfg.model.test_cfg}\")\n",
    "        misclassified = []\n",
    "\n",
    "        # 데이터셋 순회\n",
    "        for idx in range(len(self.dataset)):\n",
    "            try:\n",
    "                data = self.dataset[idx]\n",
    "            except Exception as e:\n",
    "                print(f\"Error accessing dataset index {idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # 첫 번째 샘플의 데이터 구조 출력 (디버깅 용도)\n",
    "            if idx == 0:\n",
    "                print(f\"Data structure example: {data}\")\n",
    "                print(f\"Metainfo: {self.dataset.metainfo}\")\n",
    "\n",
    "            # data_samples 추출\n",
    "            data_samples = data.get('data_samples', None)\n",
    "            if data_samples is None:\n",
    "                print(f\"Warning: data_samples is missing for index {idx}\")\n",
    "                continue\n",
    "\n",
    "            # img_path는 data_samples의 속성으로 접근\n",
    "            img_path = getattr(data_samples, 'img_path', '')\n",
    "            if not img_path:\n",
    "                print(f\"Warning: img_path is missing in data_samples for index {idx}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Image {img_path} could not be read.\")\n",
    "                continue\n",
    "\n",
    "            # Ground Truth 추출\n",
    "            gt_instances = getattr(data_samples, 'gt_instances', None)\n",
    "            if gt_instances is None:\n",
    "                print(f\"Warning: gt_instances is missing in data_samples for index {idx}\")\n",
    "                continue\n",
    "\n",
    "            gt_labels = getattr(gt_instances, 'labels', [])\n",
    "            gt_bboxes = getattr(gt_instances, 'bboxes', [])\n",
    "\n",
    "            # 텐서를 리스트나 넘파이 배열로 변환\n",
    "            if isinstance(gt_labels, torch.Tensor):\n",
    "                gt_labels = gt_labels.cpu().numpy().tolist()\n",
    "            if isinstance(gt_bboxes, torch.Tensor):\n",
    "                gt_bboxes = gt_bboxes.cpu().numpy().tolist()\n",
    "\n",
    "            if not gt_labels or not gt_bboxes:\n",
    "                print(f\"Warning: No ground truth labels or bboxes for image {img_path}.\")\n",
    "                continue\n",
    "\n",
    "            # 모델 추론 - test_pipeline을 전달하지 않음\n",
    "            try:\n",
    "                results = inference_detector(runner.model, img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during inference for image {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # 결과 처리 (bbox 결과 가정)\n",
    "            if isinstance(results, tuple):\n",
    "                bbox_result = results[0]\n",
    "            else:\n",
    "                bbox_result = results\n",
    "\n",
    "            # 예측된 클래스 라벨 수집\n",
    "            pred_labels = []\n",
    "            for class_id, bboxes in enumerate(bbox_result, start=1):\n",
    "                for bbox in bboxes:\n",
    "                    pred_labels.append(class_id)\n",
    "\n",
    "            # Ground Truth와 예측된 라벨 비교\n",
    "            gt_set = set(gt_labels)\n",
    "            pred_set = set(pred_labels)\n",
    "            misclass = not gt_set.issubset(pred_set)\n",
    "\n",
    "            if misclass:\n",
    "                # 오분류 정도를 나타내는 오류 점수 계산 (대칭 차집합의 크기)\n",
    "                error_score = len(gt_set.symmetric_difference(pred_set))\n",
    "                misclassified.append((error_score, img_path, img, results, gt_bboxes, gt_labels))\n",
    "\n",
    "        if not misclassified:\n",
    "            print(\"TopMisclassifiedImagesHook: No misclassified images found.\")\n",
    "            return\n",
    "\n",
    "        # 오류 점수를 기준으로 내림차순 정렬\n",
    "        misclassified = sorted(misclassified, key=lambda x: x[0], reverse=True)\n",
    "        top_misclassified = misclassified[:self.top_k]\n",
    "\n",
    "        # 상위 오분류된 이미지를 WandB에 로그\n",
    "        for error_score, img_path, img, results, gt_bboxes, gt_labels in top_misclassified:\n",
    "            # 이미지에 예측 결과와 Ground Truth를 그려줍니다.\n",
    "            fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Ground Truth 바운딩 박스 그리기\n",
    "            for bbox, label in zip(gt_bboxes, gt_labels):\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                width, height = x2 - x1, y2 - y1\n",
    "                rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='g', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(x1, y1 - 5, f\"GT: {self.dataset.metainfo['classes'][label - 1]}\", color='green', fontsize=12, backgroundcolor='black')\n",
    "\n",
    "            # 예측된 바운딩 박스 그리기\n",
    "            for class_id, bboxes in enumerate(results, start=1):\n",
    "                for bbox in bboxes:\n",
    "                    score = bbox[-1]\n",
    "                    if score < self.score_thr:\n",
    "                        continue\n",
    "                    x1, y1, x2, y2 = bbox[:4]\n",
    "                    width, height = x2 - x1, y2 - y1\n",
    "                    rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.text(x1, y1 - 5, f\"{self.dataset.metainfo['classes'][class_id - 1]}: {score:.2f}\", color='yellow', fontsize=12, backgroundcolor='black')\n",
    "\n",
    "            ax.axis('off')\n",
    "\n",
    "            # 시각화된 이미지를 파일로 저장\n",
    "            vis_path = os.path.join(self.work_dir, f\"misclassified_{os.path.basename(img_path)}.png\")\n",
    "            fig.savefig(vis_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close(fig)\n",
    "\n",
    "            # WandB에 시각화된 이미지 로그\n",
    "            try:\n",
    "                runner.logger.experiment.log({\n",
    "                    \"Top Misclassified Images\": wandb.Image(vis_path, caption=f\"Path: {img_path} | Error Score: {error_score}\")\n",
    "                })\n",
    "                print(f\"Logged misclassified image: {vis_path} to WandB\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error logging to WandB: {e}\")\n",
    "\n",
    "        print(f\"WandB에 상위 {self.top_k}개의 오분류 이미지를 로그했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정 파일 로드\n",
    "config_path = './projects/CO-DETR/configs/codino/co_dino_5scale_swin_l_16xb1_1x_coco.py'  # DINO 설정 파일 경로\n",
    "cfg = Config.fromfile(config_path)\n",
    "\n",
    "# 작업 디렉토리 설정\n",
    "work_dir = './work_dirs/co_dino_custom'  # 로그와 모델을 저장할 디렉토리 경로\n",
    "cfg.work_dir = work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 설정\n",
    "classes = (\n",
    "    \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\",\n",
    "    \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"\n",
    ")\n",
    "num_classes = len(classes)  # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증 데이터셋 분할 (멀티라벨 스트라티파이드 분할)\n",
    "original_ann_file = '/data/ephemeral/home/dataset/train.json'  # 전체 데이터 어노테이션 파일 경로\n",
    "\n",
    "with open(original_ann_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# 이미지 ID 리스트 가져오기\n",
    "image_ids = [image['id'] for image in annotations['images']]\n",
    "\n",
    "# 이미지 ID와 해당 이미지에 포함된 클래스 목록 매핑\n",
    "image_id_to_classes = {image_id: [] for image_id in image_ids}\n",
    "for ann in annotations['annotations']:\n",
    "    image_id = ann['image_id']\n",
    "    category_id = ann['category_id']\n",
    "    if category_id not in image_id_to_classes[image_id]:\n",
    "        image_id_to_classes[image_id].append(category_id)\n",
    "\n",
    "# 멀티라벨 인코딩을 위한 이진 매트릭스 생성\n",
    "label_matrix = np.zeros((len(image_ids), num_classes))\n",
    "image_id_to_index = {image_id: idx for idx, image_id in enumerate(image_ids)}\n",
    "for image_id, class_ids in image_id_to_classes.items():\n",
    "    idx = image_id_to_index[image_id]\n",
    "    for class_id in class_ids:\n",
    "        label_matrix[idx, class_id - 1] = 1  # category_id는 1부터 시작\n",
    "\n",
    "# 멀티라벨 스트라티파이드 셔플 스플릿 사용\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.9, random_state=42)  # 80:20 분할\n",
    "train_indices, val_indices = next(msss.split(image_ids, label_matrix))\n",
    "\n",
    "# 인덱스를 이미지 ID로 변환\n",
    "train_ids = [image_ids[idx] for idx in train_indices]\n",
    "val_ids = [image_ids[idx] for idx in val_indices]\n",
    "\n",
    "# 학습 및 검증 데이터 어노테이션 생성\n",
    "train_annotations = {\n",
    "    'images': [img for img in annotations['images'] if img['id'] in train_ids],\n",
    "    'annotations': [ann for ann in annotations['annotations'] if ann['image_id'] in train_ids],\n",
    "    'categories': annotations['categories']\n",
    "}\n",
    "val_annotations = {\n",
    "    'images': [img for img in annotations['images'] if img['id'] in val_ids],\n",
    "    'annotations': [ann for ann in annotations['annotations'] if ann['image_id'] in val_ids],\n",
    "    'categories': annotations['categories']\n",
    "}\n",
    "\n",
    "# 분할된 어노테이션을 파일로 저장\n",
    "train_ann_file = '/data/ephemeral/home/dataset/train_split.json'\n",
    "val_ann_file = '/data/ephemeral/home/dataset/val_split.json'\n",
    "\n",
    "with open(train_ann_file, 'w') as f:\n",
    "    json.dump(train_annotations, f)\n",
    "with open(val_ann_file, 'w') as f:\n",
    "    json.dump(val_annotations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어노테이션 파일 수정: category_id를 1부터 시작하도록 조정\n",
    "def increment_category_id(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 'categories' 섹션의 'id'를 1부터 시작하도록 수정\n",
    "    id_mapping = {}\n",
    "    for category in data['categories']:\n",
    "        old_id = category['id']\n",
    "        new_id = old_id + 1\n",
    "        id_mapping[old_id] = new_id\n",
    "        category['id'] = new_id\n",
    "\n",
    "    # 'annotations' 섹션의 'category_id'를 매핑에 따라 수정\n",
    "    for ann in data['annotations']:\n",
    "        old_cat_id = ann['category_id']\n",
    "        if old_cat_id in id_mapping:\n",
    "            ann['category_id'] = id_mapping[old_cat_id]\n",
    "        else:\n",
    "            print(f\"Warning: annotation id {ann['id']} has invalid category_id {old_cat_id}\")\n",
    "\n",
    "    # 수정된 데이터를 원래 파일에 저장\n",
    "    with open(annotation_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# 어노테이션 파일에 category_id를 1부터 시작하도록 수정\n",
    "increment_category_id(train_ann_file)\n",
    "increment_category_id(val_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/baseline/mmdetection/wandb/run-20241013_195245-objx407x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/objx407x' target=\"_blank\">co_dino_5scale_swin_l_lsj_16xb1_1x_coco_20241013_195240</a></strong> to <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/objx407x' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection/runs/objx407x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Run Initialized: co_dino_5scale_swin_l_lsj_16xb1_1x_coco_20241013_195240\n"
     ]
    }
   ],
   "source": [
    "# EarlyStoppingHook 추가\n",
    "early_stopping_hook = dict(\n",
    "    type='EarlyStoppingHook',\n",
    "    monitor='bbox_mAP',\n",
    "    rule='greater',\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    check_finite=True,\n",
    "    stopping_threshold=None\n",
    ")\n",
    "\n",
    "# cfg.default_hooks에 EarlyStoppingHook 추가\n",
    "cfg.default_hooks.update(\n",
    "    early_stopping=early_stopping_hook\n",
    ")\n",
    "\n",
    "# WandB 초기화 (Runner 전에)\n",
    "run_name = f'co_dino_5scale_swin_l_lsj_16xb1_1x_coco_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "wandb.init(\n",
    "    project='Object_detection',\n",
    "    name=run_name,\n",
    "    config=cfg.to_dict(),\n",
    "    allow_val_change=True,\n",
    "    reinit=True\n",
    ")\n",
    "print(f\"WandB Run Initialized: {run_name}\")\n",
    "\n",
    "# WandbVisBackend 설정\n",
    "wandb_vis_backend = dict(\n",
    "    type='WandbVisBackend',\n",
    "    save_dir=cfg.work_dir,  # 저장할 디렉토리\n",
    "    init_kwargs=dict(\n",
    "        project='Object_detection',  # WandB 프로젝트 이름\n",
    "        name=run_name,                # 고유한 실행 이름\n",
    "        allow_val_change=True         # 설정 값 변경 허용\n",
    "    ),\n",
    "    define_metric_cfg=None,\n",
    "    commit=True,\n",
    "    log_code_name=None,\n",
    "    watch_kwargs=None\n",
    ")\n",
    "\n",
    "# Visualizer 설정을 Runner의 visualizer 필드로 추가\n",
    "cfg.visualizer = dict(\n",
    "    type='Visualizer',\n",
    "    vis_backends=[\n",
    "        wandb_vis_backend  # WandbVisBackend 추가\n",
    "    ],\n",
    "    name='visualizer'  # Visualizer 이름 (옵션)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 루트 경로 수정 및 데이터 파이프라인 수정\n",
    "train_data_root = '/data/ephemeral/home/dataset/'  # 학습 데이터 경로\n",
    "cfg.train_dataloader.dataset.ann_file = train_ann_file  # 수정된 부분\n",
    "cfg.train_dataloader.dataset.data_prefix = dict(img=train_data_root)  # 수정된 부분\n",
    "\n",
    "cfg.val_dataloader.dataset.ann_file = val_ann_file  # 수정된 부분\n",
    "cfg.val_dataloader.dataset.data_prefix = dict(img=train_data_root)  # 수정된 부분\n",
    "\n",
    "# 클래스 설정을 데이터셋의 metainfo에 추가\n",
    "cfg.train_dataloader.dataset.metainfo = dict(classes=classes)  # 수정된 부분\n",
    "cfg.val_dataloader.dataset.metainfo = dict(classes=classes)    # 수정된 부분\n",
    "\n",
    "# 데이터 파이프라인 수정: 마스크 관련 부분 제거\n",
    "for pipeline in cfg.train_dataloader.dataset.pipeline:\n",
    "    if pipeline['type'] == 'LoadAnnotations':\n",
    "        pipeline['with_mask'] = False\n",
    "\n",
    "for pipeline in cfg.val_dataloader.dataset.pipeline:\n",
    "    if pipeline['type'] == 'LoadAnnotations':\n",
    "        pipeline['with_mask'] = False\n",
    "\n",
    "# 클래스 수 수정\n",
    "# bbox_head가 리스트인 경우 모든 헤드에 대해 num_classes 설정\n",
    "if isinstance(cfg.model.bbox_head, list):\n",
    "    for head in cfg.model.bbox_head:\n",
    "        head['num_classes'] = num_classes\n",
    "else:\n",
    "    cfg.model.bbox_head['num_classes'] = num_classes\n",
    "\n",
    "# roi_head 내의 bbox_head도 설정\n",
    "if isinstance(cfg.model.roi_head, list):\n",
    "    for roi_head in cfg.model.roi_head:\n",
    "        if hasattr(roi_head, 'bbox_head'):\n",
    "            roi_head.bbox_head.num_classes = num_classes\n",
    "else:\n",
    "    if hasattr(cfg.model.roi_head, 'bbox_head'):\n",
    "        cfg.model.roi_head.bbox_head.num_classes = num_classes\n",
    "\n",
    "# query_head도 num_classes 설정\n",
    "if isinstance(cfg.model.query_head, list):\n",
    "    for q_head in cfg.model.query_head:\n",
    "        q_head.num_classes = num_classes\n",
    "else:\n",
    "    cfg.model.query_head.num_classes = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 관련 헤드에 대해 num_classes가 올바르게 설정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 추가: 모델의 모든 관련 헤드에 num_classes가 올바르게 설정되었는지 확인\n",
    "def verify_num_classes(cfg, num_classes):\n",
    "    # bbox_head\n",
    "    if isinstance(cfg.model.bbox_head, list):\n",
    "        for head in cfg.model.bbox_head:\n",
    "            assert head.num_classes == num_classes, \"bbox_head num_classes 설정 오류\"\n",
    "    else:\n",
    "        assert cfg.model.bbox_head.num_classes == num_classes, \"bbox_head num_classes 설정 오류\"\n",
    "\n",
    "    # roi_head.bbox_head\n",
    "    if isinstance(cfg.model.roi_head, list):\n",
    "        for roi_head in cfg.model.roi_head:\n",
    "            if hasattr(roi_head, 'bbox_head'):\n",
    "                assert roi_head.bbox_head.num_classes == num_classes, \"roi_head.bbox_head num_classes 설정 오류\"\n",
    "    else:\n",
    "        if hasattr(cfg.model.roi_head, 'bbox_head'):\n",
    "            assert cfg.model.roi_head.bbox_head.num_classes == num_classes, \"roi_head.bbox_head num_classes 설정 오류\"\n",
    "\n",
    "    # query_head\n",
    "    if isinstance(cfg.model.query_head, list):\n",
    "        for q_head in cfg.model.query_head:\n",
    "            assert q_head.num_classes == num_classes, \"query_head num_classes 설정 오류\"\n",
    "    else:\n",
    "        assert cfg.model.query_head.num_classes == num_classes, \"query_head num_classes 설정 오류\"\n",
    "\n",
    "    print(\"모든 관련 헤드에 대해 num_classes가 올바르게 설정되었습니다.\")\n",
    "\n",
    "verify_num_classes(cfg, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 혼합 정밀도 학습 사용 설정\n",
    "use_amp = False  # 자동 혼합 정밀도(AMP) 학습 사용 여부\n",
    "if use_amp:\n",
    "    cfg.optim_wrapper.type = 'AmpOptimWrapper'\n",
    "    cfg.optim_wrapper.loss_scale = 'dynamic'\n",
    "\n",
    "# 학습률 자동 스케일링 설정\n",
    "auto_scale_lr = False  # 학습률 자동 스케일링 사용 여부\n",
    "if auto_scale_lr:\n",
    "    if 'auto_scale_lr' in cfg and 'enable' in cfg.auto_scale_lr and 'base_batch_size' in cfg.auto_scale_lr:\n",
    "        cfg.auto_scale_lr.enable = True\n",
    "    else:\n",
    "        raise RuntimeError('설정 파일에 \"auto_scale_lr\" 또는 필요한 키가 없습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 설정 최적화\n",
    "cfg.train_dataloader.batch_size = 2  # 배치 사이즈를 2로 설정\n",
    "cfg.val_dataloader.batch_size = 2\n",
    "\n",
    "cfg.train_dataloader.num_workers = 2  # 워커 수 줄이기\n",
    "cfg.val_dataloader.num_workers = 2\n",
    "\n",
    "# Prefetch factor와 persistent_workers 설정\n",
    "cfg.train_dataloader.prefetch_factor = 2\n",
    "cfg.train_dataloader.persistent_workers = False\n",
    "cfg.val_dataloader.prefetch_factor = 2\n",
    "cfg.val_dataloader.persistent_workers = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 설정:\n",
      "{'type': 'CocoMetric', 'ann_file': '/data/ephemeral/home/dataset/val_split.json', 'metric': ['bbox']}\n",
      "{'ann_file': '/data/ephemeral/home/dataset/val_split.json', 'interval': 1, 'metric': 'bbox', 'save_best': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# val_evaluator 설정을 사용자 정의 검증 어노테이션 파일로 수정\n",
    "cfg.val_evaluator = dict(\n",
    "    type='CocoMetric',\n",
    "    ann_file=val_ann_file,   # 사용자 정의 검증 어노테이션 파일 경로\n",
    "    metric=['bbox']\n",
    ")\n",
    "\n",
    "# 또는, cfg.evaluation 섹션에 ann_file을 추가\n",
    "if 'evaluation' in cfg:\n",
    "    cfg.evaluation['ann_file'] = val_ann_file\n",
    "else:\n",
    "    cfg.evaluation = dict(\n",
    "        ann_file=val_ann_file,\n",
    "        interval=1,\n",
    "        metric='bbox',\n",
    "        save_best='auto'\n",
    "    )\n",
    "\n",
    "print(\"Evaluation 설정:\")\n",
    "print(cfg.val_evaluator)\n",
    "print(cfg.evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/13 19:52:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 2057306621\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.1+cu116\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu116\n",
      "    OpenCV: 4.8.1\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 2057306621\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "10/13 19:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16)\n",
      "backend_args = None\n",
      "batch_augments = [\n",
      "    dict(pad_mask=True, size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='BatchFixedSizePad'),\n",
      "]\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False, imports=[\n",
      "        'projects.CO-DETR.codetr',\n",
      "    ])\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        _scope_='mmdet',\n",
      "        by_epoch=True,\n",
      "        interval=1,\n",
      "        max_keep_ckpts=3,\n",
      "        type='CheckpointHook'),\n",
      "    early_stopping=dict(\n",
      "        check_finite=True,\n",
      "        min_delta=0.001,\n",
      "        monitor='bbox_mAP',\n",
      "        patience=5,\n",
      "        rule='greater',\n",
      "        stopping_threshold=None,\n",
      "        type='EarlyStoppingHook'),\n",
      "    logger=dict(_scope_='mmdet', interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(_scope_='mmdet', type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(_scope_='mmdet', type='DistSamplerSeedHook'),\n",
      "    timer=dict(_scope_='mmdet', type='IterTimerHook'),\n",
      "    visualization=dict(_scope_='mmdet', type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "evaluation = dict(\n",
      "    ann_file='/data/ephemeral/home/dataset/val_split.json',\n",
      "    interval=1,\n",
      "    metric='bbox',\n",
      "    save_best='auto')\n",
      "image_size = (\n",
      "    1024,\n",
      "    1024,\n",
      ")\n",
      "load_from = None\n",
      "load_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(\n",
      "        allow_negative_crop=True,\n",
      "        crop_size=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        crop_type='absolute_range',\n",
      "        recompute_bbox=True,\n",
      "        type='RandomCrop'),\n",
      "    dict(min_gt_bbox_wh=(\n",
      "        0.01,\n",
      "        0.01,\n",
      "    ), type='FilterAnnotations'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Pad'),\n",
      "]\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(\n",
      "    _scope_='mmdet', by_epoch=True, type='LogProcessor', window_size=50)\n",
      "loss_lambda = 2.0\n",
      "max_epochs = 100\n",
      "max_iters = 270000\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        convert_weights=True,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            18,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.3,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=192,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            6,\n",
      "            12,\n",
      "            24,\n",
      "            48,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        pretrain_img_size=384,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer',\n",
      "        window_size=12,\n",
      "        with_cp=False),\n",
      "    bbox_head=[\n",
      "        dict(\n",
      "            anchor_generator=dict(\n",
      "                octave_base_scale=8,\n",
      "                ratios=[\n",
      "                    1.0,\n",
      "                ],\n",
      "                scales_per_octave=1,\n",
      "                strides=[\n",
      "                    4,\n",
      "                    8,\n",
      "                    16,\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                ],\n",
      "                type='AnchorGenerator'),\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            feat_channels=256,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=24.0, type='GIoULoss'),\n",
      "            loss_centerness=dict(\n",
      "                loss_weight=12.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "            loss_cls=dict(\n",
      "                alpha=0.25,\n",
      "                gamma=2.0,\n",
      "                loss_weight=12.0,\n",
      "                type='FocalLoss',\n",
      "                use_sigmoid=True),\n",
      "            num_classes=10,\n",
      "            stacked_convs=1,\n",
      "            type='CoATSSHead'),\n",
      "    ],\n",
      "    data_preprocessor=dict(\n",
      "        batch_augments=None,\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=False,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    eval_module='detr',\n",
      "    neck=dict(\n",
      "        act_cfg=None,\n",
      "        in_channels=[\n",
      "            192,\n",
      "            384,\n",
      "            768,\n",
      "            1536,\n",
      "        ],\n",
      "        kernel_size=1,\n",
      "        norm_cfg=dict(num_groups=32, type='GN'),\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='ChannelMapper'),\n",
      "    query_head=dict(\n",
      "        as_two_stage=True,\n",
      "        dn_cfg=dict(\n",
      "            box_noise_scale=1.0,\n",
      "            group_cfg=dict(dynamic=True, num_dn_queries=100, num_groups=None),\n",
      "            label_noise_scale=0.5),\n",
      "        in_channels=2048,\n",
      "        loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "        num_classes=10,\n",
      "        num_query=900,\n",
      "        positional_encoding=dict(\n",
      "            normalize=True,\n",
      "            num_feats=128,\n",
      "            temperature=20,\n",
      "            type='SinePositionalEncoding'),\n",
      "        transformer=dict(\n",
      "            decoder=dict(\n",
      "                num_layers=6,\n",
      "                return_intermediate=True,\n",
      "                transformerlayers=dict(\n",
      "                    attn_cfgs=[\n",
      "                        dict(\n",
      "                            dropout=0.0,\n",
      "                            embed_dims=256,\n",
      "                            num_heads=8,\n",
      "                            type='MultiheadAttention'),\n",
      "                        dict(\n",
      "                            dropout=0.0,\n",
      "                            embed_dims=256,\n",
      "                            num_levels=5,\n",
      "                            type='MultiScaleDeformableAttention'),\n",
      "                    ],\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_dropout=0.0,\n",
      "                    operation_order=(\n",
      "                        'self_attn',\n",
      "                        'norm',\n",
      "                        'cross_attn',\n",
      "                        'norm',\n",
      "                        'ffn',\n",
      "                        'norm',\n",
      "                    ),\n",
      "                    type='DetrTransformerDecoderLayer'),\n",
      "                type='DinoTransformerDecoder'),\n",
      "            encoder=dict(\n",
      "                num_layers=6,\n",
      "                transformerlayers=dict(\n",
      "                    attn_cfgs=dict(\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        num_levels=5,\n",
      "                        type='MultiScaleDeformableAttention'),\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_dropout=0.0,\n",
      "                    operation_order=(\n",
      "                        'self_attn',\n",
      "                        'norm',\n",
      "                        'ffn',\n",
      "                        'norm',\n",
      "                    ),\n",
      "                    type='BaseTransformerLayer'),\n",
      "                type='DetrTransformerEncoder',\n",
      "                with_cp=6),\n",
      "            num_co_heads=2,\n",
      "            num_feature_levels=5,\n",
      "            type='CoDinoTransformer',\n",
      "            with_coord_feat=False),\n",
      "        type='CoDINOHead'),\n",
      "    roi_head=[\n",
      "        dict(\n",
      "            bbox_head=dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=120.0, type='GIoULoss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=12.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=False,\n",
      "                reg_decoded_bbox=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            bbox_roi_extractor=dict(\n",
      "                featmap_strides=[\n",
      "                    4,\n",
      "                    8,\n",
      "                    16,\n",
      "                    32,\n",
      "                    64,\n",
      "                ],\n",
      "                finest_scale=56,\n",
      "                out_channels=256,\n",
      "                roi_layer=dict(\n",
      "                    output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "                type='SingleRoIExtractor'),\n",
      "            type='CoStandardRoIHead'),\n",
      "    ],\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            octave_base_scale=4,\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales_per_octave=3,\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "                128,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=12.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=12.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=[\n",
      "        dict(max_per_img=300, nms=dict(iou_threshold=0.8, type='soft_nms')),\n",
      "        dict(\n",
      "            rcnn=dict(\n",
      "                max_per_img=100,\n",
      "                nms=dict(iou_threshold=0.5, type='nms'),\n",
      "                score_thr=0.0),\n",
      "            rpn=dict(\n",
      "                max_per_img=1000,\n",
      "                min_bbox_size=0,\n",
      "                nms=dict(iou_threshold=0.7, type='nms'),\n",
      "                nms_pre=1000)),\n",
      "        dict(\n",
      "            max_per_img=100,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=1000,\n",
      "            score_thr=0.0),\n",
      "    ],\n",
      "    train_cfg=[\n",
      "        dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='FocalLossCost', weight=2.0),\n",
      "                    dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),\n",
      "                    dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                ],\n",
      "                type='HungarianAssigner')),\n",
      "        dict(\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            rpn=dict(\n",
      "                allowed_border=-1,\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=True,\n",
      "                    min_pos_iou=0.3,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=False,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    type='RandomSampler')),\n",
      "            rpn_proposal=dict(\n",
      "                max_per_img=1000,\n",
      "                min_bbox_size=0,\n",
      "                nms=dict(iou_threshold=0.7, type='nms'),\n",
      "                nms_pre=4000)),\n",
      "        dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(topk=9, type='ATSSAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1),\n",
      "    ],\n",
      "    type='CoDETR',\n",
      "    use_lsj=False)\n",
      "num_classes = 10\n",
      "num_dec_layer = 6\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.1, norm_type=2),\n",
      "    optimizer=dict(lr=0.0001, type='AdamW', weight_decay=0.0001),\n",
      "    paramwise_cfg=dict(custom_keys=dict(backbone=dict(lr_mult=0.1))),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=100,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth'\n",
      "resume = False\n",
      "test_cfg = dict(_scope_='mmdet', type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    _scope_='mmdet',\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='/data/ephemeral/home/dataset/train_split.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/data/ephemeral/home/dataset/'),\n",
      "        data_root='data/coco/',\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                transforms=[\n",
      "                    [\n",
      "                        dict(\n",
      "                            keep_ratio=True,\n",
      "                            scales=[\n",
      "                                (\n",
      "                                    480,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    512,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    544,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    576,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    608,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    640,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    672,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    704,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    736,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    768,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    800,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                            ],\n",
      "                            type='RandomChoiceResize'),\n",
      "                    ],\n",
      "                    [\n",
      "                        dict(\n",
      "                            keep_ratio=True,\n",
      "                            scales=[\n",
      "                                (\n",
      "                                    400,\n",
      "                                    4200,\n",
      "                                ),\n",
      "                                (\n",
      "                                    500,\n",
      "                                    4200,\n",
      "                                ),\n",
      "                                (\n",
      "                                    600,\n",
      "                                    4200,\n",
      "                                ),\n",
      "                            ],\n",
      "                            type='RandomChoiceResize'),\n",
      "                        dict(\n",
      "                            allow_negative_crop=True,\n",
      "                            crop_size=(\n",
      "                                384,\n",
      "                                600,\n",
      "                            ),\n",
      "                            crop_type='absolute_range',\n",
      "                            type='RandomCrop'),\n",
      "                        dict(\n",
      "                            keep_ratio=True,\n",
      "                            scales=[\n",
      "                                (\n",
      "                                    480,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    512,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    544,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    576,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    608,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    640,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    672,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    704,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    736,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    768,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                                (\n",
      "                                    800,\n",
      "                                    1333,\n",
      "                                ),\n",
      "                            ],\n",
      "                            type='RandomChoiceResize'),\n",
      "                    ],\n",
      "                ],\n",
      "                type='RandomChoice'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=False,\n",
      "    prefetch_factor=2,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            400,\n",
      "                            4200,\n",
      "                        ),\n",
      "                        (\n",
      "                            500,\n",
      "                            4200,\n",
      "                        ),\n",
      "                        (\n",
      "                            600,\n",
      "                            4200,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "                dict(\n",
      "                    allow_negative_crop=True,\n",
      "                    crop_size=(\n",
      "                        384,\n",
      "                        600,\n",
      "                    ),\n",
      "                    crop_type='absolute_range',\n",
      "                    type='RandomCrop'),\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "        ],\n",
      "        type='RandomChoice'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(_scope_='mmdet', type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        ann_file='/data/ephemeral/home/dataset/val_split.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/data/ephemeral/home/dataset/'),\n",
      "        data_root='data/coco/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=False,\n",
      "    prefetch_factor=2,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='/data/ephemeral/home/dataset/val_split.json',\n",
      "    metric=[\n",
      "        'bbox',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(_scope_='mmdet', type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='Visualizer',\n",
      "    vis_backends=[\n",
      "        dict(\n",
      "            commit=True,\n",
      "            define_metric_cfg=None,\n",
      "            init_kwargs=dict(\n",
      "                allow_val_change=True,\n",
      "                name='co_dino_5scale_swin_l_lsj_16xb1_1x_coco_20241013_195240',\n",
      "                project='Object_detection'),\n",
      "            log_code_name=None,\n",
      "            save_dir='./work_dirs/co_dino_custom',\n",
      "            type='WandbVisBackend',\n",
      "            watch_kwargs=None),\n",
      "    ])\n",
      "work_dir = './work_dirs/co_dino_custom'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:objx407x) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">co_dino_5scale_swin_l_lsj_16xb1_1x_coco_20241013_195240</strong> at: <a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/objx407x' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection/runs/objx407x</a><br/> View project at: <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241013_195245-objx407x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:objx407x). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./work_dirs/co_dino_custom/wandb/run-20241013_195248-3figy7z2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/3figy7z2' target=\"_blank\">co_dino_5scale_swin_l_lsj_16xb1_1x_coco_20241013_195240</a></strong> to <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/youngtae0818-naver/Object_detection' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/youngtae0818-naver/Object_detection/runs/3figy7z2' target=\"_blank\">https://wandb.ai/youngtae0818-naver/Object_detection/runs/3figy7z2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/baseline/mmdetection/projects/CO-DETR/codetr/transformer.py:1325: UserWarning: If you want to reduce GPU memory usage,                               please install fairscale by executing the                               following command: pip install fairscale.\n",
      "  warnings.warn('If you want to reduce GPU memory usage, \\\n",
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/dense_heads/anchor_head.py:108: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/13 19:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "10/13 19:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      "(LOWEST      ) EarlyStoppingHook                  \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 러너 생성\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "# InitHook 등록 (높은 우선순위)\n",
    "runner.register_hook(\n",
    "    InitHook(),\n",
    "    priority='VERY_HIGH'  # 매우 높은 우선순위로 설정\n",
    ")\n",
    "\n",
    "# TopMisclassifiedImagesHook 등록 (일반 우선순위)\n",
    "runner.register_hook(\n",
    "    TopMisclassifiedImagesHook(\n",
    "        dataset=runner.val_dataloader.dataset,\n",
    "        ann_file=val_ann_file,\n",
    "        work_dir=work_dir,\n",
    "        top_k=20,\n",
    "        score_thr=0.3\n",
    "    ),\n",
    "    priority='NORMAL'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 레이어를 동결\n",
    "for name, param in runner.model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 필요한 레이어 Unfreeze\n",
    "# bbox_head Unfreeze\n",
    "for param in runner.model.bbox_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# backbone의 마지막 두 레이어 Unfreeze\n",
    "for name, param in runner.model.backbone.named_parameters():\n",
    "    if 'stage3' in name or 'stage4' in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "# query_head Unfreeze\n",
    "for name, param in runner.model.query_head.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# roi_head Unfreeze\n",
    "for name, param in runner.model.roi_head.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# neck Unfreeze\n",
    "for name, param in runner.model.neck.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# rpn_head Unfreeze\n",
    "for name, param in runner.model.rpn_head.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Optimizer 설정 수정\n",
    "cfg.optim_wrapper.paramwise_cfg = dict(\n",
    "    custom_keys={\n",
    "        'backbone.stage3': dict(lr_mult=0.1),\n",
    "        'backbone.stage4': dict(lr_mult=0.1),\n",
    "        'neck': dict(lr_mult=1.0),\n",
    "        'query_head': dict(lr_mult=1.0),\n",
    "        'bbox_head': dict(lr_mult=1.0),\n",
    "        'roi_head': dict(lr_mult=1.0),\n",
    "        'rpn_head': dict(lr_mult=1.0)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 학습 시작 전에 검증 어노테이션 파일 존재 여부 확인\n",
    "if not os.path.exists(val_ann_file):\n",
    "    raise FileNotFoundError(f'Validation annotation file not found: {val_ann_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.patch_embed.projection.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.patch_embed.projection.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.patch_embed.norm.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.patch_embed.norm.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.0.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.blocks.1.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.downsample.norm.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.downsample.norm.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.0.downsample.reduction.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.0.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.blocks.1.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.downsample.norm.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.downsample.norm.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.1.downsample.reduction.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.0.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.1.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.2.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.3.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.4.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.5.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.6.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.7.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.8.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.9.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.10.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.11.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.12.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.13.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.14.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.15.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.16.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.blocks.17.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.downsample.norm.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.downsample.norm.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.2.downsample.reduction.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.0.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.attn.w_msa.qkv.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.attn.w_msa.qkv.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.attn.w_msa.proj.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.attn.w_msa.proj.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.ffn.layers.0.0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.ffn.layers.0.0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.ffn.layers.1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.stages.3.blocks.1.ffn.layers.1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm0.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm0.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm1.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm1.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm2.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm2.bias is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm3.weight is skipped since its requires_grad=False\n",
      "10/13 19:53:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.norm3.bias is skipped since its requires_grad=False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'score_thr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 학습 시작\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 학습 완료 후 단일 이미지 테스트 (선택 사항)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m single_img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/ephemeral/home/dataset/train/0003.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:1745\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_val_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_val_loop(\n\u001b[1;32m   1743\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_val_loop)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;66;03m# TODO: add a contextmanager to avoid calling `before_run` many times\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbefore_run\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# initialize the model weights\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_model_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:1839\u001b[0m, in \u001b[0;36mRunner.call_hook\u001b[0;34m(self, fn_name, **kwargs)\u001b[0m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(hook, fn_name):\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1839\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1841\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mInitHook.before_run\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 필수 필드가 누락되지 않도록 확인 및 추가\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(runner\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtest_cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore_thr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m     runner\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtest_cfg\u001b[38;5;241m.\u001b[39mscore_thr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m  \u001b[38;5;66;03m# 기본값 설정\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitHook: Added \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore_thr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to test_cfg with default value 0.05.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitHook: runner.cfg.model.test_cfg has been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'score_thr'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습 시작\n",
    "runner.train()\n",
    "\n",
    "# 학습 완료 후 단일 이미지 테스트 (선택 사항)\n",
    "single_img_path = '/data/ephemeral/home/dataset/train/0003.jpg'\n",
    "img = cv2.imread(single_img_path)\n",
    "if img is not None:\n",
    "    try:\n",
    "        result = inference_detector(runner.model, img)\n",
    "        print(f\"Inference result for {single_img_path}: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference for {single_img_path}: {e}\")\n",
    "else:\n",
    "    print(f\"Image {single_img_path} could not be read.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
